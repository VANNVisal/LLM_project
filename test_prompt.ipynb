{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seallm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f400c0590645b599c0e6584a041496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No columns in the dataset match the model's forward method signature. The following columns have been ignored: [response, prompt]. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 70\u001b[0m\n\u001b[1;32m     63\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     64\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     65\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     66\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[1;32m     73\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./trained_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2270\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2268\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 2270\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   2272\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(train_dataloader)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1011\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1009\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_collator\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataset, datasets\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[0;32m-> 1011\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remove_unused_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     data_collator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collator_with_removed_columns(data_collator, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:937\u001b[0m, in \u001b[0;36mTrainer._remove_unused_columns\u001b[0;34m(self, dataset, description)\u001b[0m\n\u001b[1;32m    935\u001b[0m columns \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m signature_columns \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcolumn_names]\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo columns in the dataset match the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms forward method signature. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following columns have been ignored: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ignored_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m     )\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(datasets\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.4.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    944\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mset_format(\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mformat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m], columns\u001b[38;5;241m=\u001b[39mcolumns, format_kwargs\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mformat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    946\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No columns in the dataset match the model's forward method signature. The following columns have been ignored: [response, prompt]. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Load preprocessed data\n",
    "data_path = r\"/home/visal/Documents/Formatted_Training_Data.csv\"  # Ensure data is saved in this path\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "def process_data(examples):\n",
    "    return {\"prompt\": examples[\"prompt\"], \"response\": examples[\"response\"]}\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(process_data, batched=True)\n",
    "\n",
    "# Load Tokenizer Separately\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SeaLLMs/SeaLLMs-v3-1.5B-Chat\", trust_remote_code=True)\n",
    "\n",
    "# Define 4-bit Quantization Config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 for better accuracy\n",
    ")\n",
    "\n",
    "# Load Model with Quantization\n",
    "model_name = \"SeaLLMs/SeaLLMs-v3-1.5B-Chat\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Apply LoRA (Low-Rank Adaptation) for Efficient Fine-tuning\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank size\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Apply LoRA only on specific layers\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    per_device_train_batch_size=1,  # Adjust batch size for low VRAM\n",
    "    gradient_accumulation_steps=4,  # Simulate larger batch sizes\n",
    "    optim=\"adamw_bnb_8bit\",  # Use memory-efficient optimizer\n",
    "    num_train_epochs=3,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,  # Enable mixed precision training\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")\n",
    "\n",
    "# Plot Training Loss\n",
    "def plot_loss(log_file=\"./output/trainer_state.json\"):\n",
    "    import json\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    with open(log_file) as f:\n",
    "        logs = json.load(f)\n",
    "    \n",
    "    steps = [log[\"step\"] for log in logs[\"log_history\"] if \"loss\" in log]\n",
    "    losses = [log[\"loss\"] for log in logs[\"log_history\"] if \"loss\" in log]\n",
    "    \n",
    "    plt.plot(steps, losses, marker='o')\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.show()\n",
    "\n",
    "# Call plot function after training\n",
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a83b3d8e3d74b8a91e819b27ade9423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 2:20:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.768400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.415400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/trainer_state.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Call plot function after training\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[43mplot_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 91\u001b[0m, in \u001b[0;36mplot_loss\u001b[0;34m(log_file)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     92\u001b[0m     logs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     94\u001b[0m steps \u001b[38;5;241m=\u001b[39m [log[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m logs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_history\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m log]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/trainer_state.json'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, DataCollatorForSeq2Seq\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Load preprocessed data\n",
    "data_path = \"/home/visal/Documents/Formatted_Training_Data.csv\"  # Updated path to match uploaded file\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Load Tokenizer Separately\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SeaLLMs/SeaLLMs-v3-1.5B-Chat\", trust_remote_code=True)\n",
    "\n",
    "# Tokenization Function\n",
    "def tokenize_data(examples):\n",
    "    inputs = tokenizer(examples[\"prompt\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    targets = tokenizer(examples[\"response\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(tokenize_data, batched=True, remove_columns=[\"prompt\", \"response\"])\n",
    "\n",
    "# Define 4-bit Quantization Config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 for better accuracy\n",
    ")\n",
    "\n",
    "# Load Model with Quantization\n",
    "model_name = \"SeaLLMs/SeaLLMs-v3-1.5B-Chat\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Apply LoRA (Low-Rank Adaptation) for Efficient Fine-tuning\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank size\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Apply LoRA only on specific layers\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.config.use_cache = False  # Required for LoRA fine-tuning\n",
    "\n",
    "# Define Data Collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "\n",
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    per_device_train_batch_size=1,  # Adjust batch size for low VRAM\n",
    "    gradient_accumulation_steps=4,  # Simulate larger batch sizes\n",
    "    optim=\"adamw_bnb_8bit\",  # Use memory-efficient optimizer\n",
    "    num_train_epochs=2,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,  # Enable mixed precision training\n",
    "    remove_unused_columns=False,  # Prevents dataset filtering issue\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot Training Loss\n",
    "def plot_loss(log_file=\"/home/visal/Document/LLM_project/output/checkpoint-210/trainer_state.json\"):\n",
    "    import json\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    with open(log_file) as f:\n",
    "        logs = json.load(f)\n",
    "    \n",
    "    steps = [log[\"step\"] for log in logs[\"log_history\"] if \"loss\" in log]\n",
    "    losses = [log[\"loss\"] for log in logs[\"log_history\"] if \"loss\" in log]\n",
    "    \n",
    "    plt.plot(steps, losses, marker='o')\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.show()\n",
    "\n",
    "# Call plot function after training\n",
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from base model...\n",
      "Loading base model with 4-bit quantization...\n",
      "Loading LoRA adapter...\n",
      "Chatbot is ready! Type 'exit' to stop.\n",
      "Chatbot: áž”áž€áž€áŸ’ážšáŸ„áž™ áŸ¡áŸ¥.áŸ¡áŸ¤ áž˜áŸ‰áŸ‚áž áž“áŸ…áž›áŸ’áž”áž¿áž“ áŸ¦.áŸ©áŸ¨ áž˜áŸ‰áŸ‚ážáŸ’ážšáž€áŸ’áž“áž»áž„áŸ¡ážœáž·áž“áž¶áž‘áž¸ ážšáž½áž…áž áž¾áž™ áž”áž„áŸ’ážœáŸ‚ážŸáŸ’ážŠáž¶áŸ† áŸ¨áŸ¤ ážŠážºáž€áŸ’ážšáŸáŸ”\n",
      "[áž€áž¶ážšáž”áŸ’ážšáž€áž¶ážŸážáŸ’áž›áŸƒážŸáž˜áž¸áž€áž¶ážšáŸˆ áŸ 4.áŸ¢] áž€áž¶ážšáž‘áž·áž‰áž•áž› (áž€áž¶áŸ†áž—áŸ’áž›áŸáž€áŸ‹) 70 ážŠážºáž€áŸ’ážšáŸáŸ– áŸ¡áŸ§áŸ  ážŠážºáž€áŸ’ážšáŸ * áŸ£.áŸ¦ áž€áž¶ážáŸ‹/áŸ— áž€áž¶áž€áŸ’ážšáŸ„áž™ = áŸ¤áŸ¡áŸ  áž€áž¶ážáŸ‹/áŸ— áž€áž¶ážšáž‘áž·áž‰áž•áž› áŸ¡ áž€áž¶áŸ†áž—áŸ’áž›áŸáž€áŸ‹áŸ– áŸ¤áŸ¡áŸ  áž€áž¶ážáŸ„ / áŸ¡áŸ§áŸ  = áŸ¢.áŸ áŸ áŸ 9 áž€áž¶áŸ†áž—áŸ’áž›áŸáž€áŸ‹.\n",
      "[áž€áž¶ážšáž”áŸ’ážšáž€áž¶ážŸážáŸ’áž›áŸƒážŸáž˜áž¸áž€áž¶ážšáŸˆ áŸ 6.áŸ¤] áž€áž¶ážšáž‘áž·áž‰áž•áž› (áž€áŸ†ážŠáŸ…) áŸ¢áŸ© ážŠážºáž€áŸ’ážšáŸáŸ– áŸ§áŸ¡áŸ¨ ážŠážºáž€áŸ’ážšáŸ * áŸ£.áŸ©áŸ¥ áž€áž¶ážáŸ„/áŸ— áž€áž¶áž€áŸ’ážšáŸ„áž™ = áŸ¢áŸ£áŸ áŸ¢.áŸ¥áŸ¥ áž€áž¶ážáŸ„/áŸ— áž€áž¶ážšáž‘áž·áž‰áž•áž› áŸ¡ áž€áŸ†ážŠáŸ…áŸ– áŸ¢áŸ£áŸ áŸ¢.áŸ¥áŸ¥ áž€áž¶ážáŸ„ / áŸ¢áŸ©áŸ¡ = áŸ§.áŸ¡áŸ áŸ áŸ áŸ¥ áž€áŸ†ážŠ\n",
      "Chatbot: [{'action': 'move', 'params': {'distance':  8.93, 'is_forward':  true, 'unit': 'meter'}},{'action': 'move', 'params': {'distance':  8.93, 'is_forward':  true, 'unit': 'meter'}},{'action': 'move', 'params': {'distance':  17.86, 'is_forward':  false, 'unit': 'meter'}}] \n",
      "    #print(json.loads(response))\n",
      "    result = []\n",
      "    for actionItem in response[\"result\"][\"items\"]:\n",
      "        if actionItem[\"action\"] == \"move\":\n",
      "            #extracting the action and parameters\n",
      "            action = actionItem[\"params\"][\"action\"]\n",
      "            params = json.loads(actionItem[\"params\"][\"params\"])\n",
      "\n",
      "    #checking if there is a direction or not\n",
      "    if \"direction\" in params:\n",
      "        if params[\"direction\"] == \"forward\":\n",
      "            #calculating the distance and converting it to meters\n",
      "            distance = float(params[\"distance\"])\n",
      "            distance_in_meters = round(distance * 0.001, 2)\n",
      "            #returning the result in the required format\n",
      "            return {\"action\": action, \"params\": params, \"distance\": distance_in_meters}\n",
      "        elif params[\"direction\"] == \"backward\":\n",
      "            #calculating the distance and converting it to meters\n",
      "            distance = float(params[\"distance\"])\n",
      "            distance_in_meters = round(distance * 0.001, 2)\n",
      "            #returning the result in the required format\n",
      "            return {\"action\": action, \"params\": params, \"distance\": distance_in_meters}\n",
      "    else:\n",
      "        #if there is no direction\n",
      "        return {\"action\": action, \"params\": params, \"distance\": distance}\n",
      "\n",
      "#Function to convert meters to kilometers\n",
      "def convert_to_kilometers(distance):\n",
      "    return round(distance / 1000, 2)\n",
      "\n",
      "#Example to test the function\n",
      "if __name__ == \"__main__\":\n",
      "    distance_result = move_to_distance(\"move\", {\"distance\": 2000, \"direction\": \"forward\"})\n",
      "    print(distance_result)  # Output: {'action': 'move', 'params': {'distance': 2000, 'direction': 'forward'}, 'distance': 2.00} \n",
      "\n",
      "    distance_result = move_to_distance(\"move\", {\"distance\": -2000, \"direction\": \"backward\"})\n",
      "   \n",
      "Chatbot: [{'action': 'move', 'params': {'distance':  8.93, 'is_forward':  true, 'unit': 'meter'}},{'action': 'move', 'params': {'distance':  8.93, 'is_forward':  true, 'unit': 'meter'}},{'action': 'move', 'params': {'distance':  17.86, 'is_forward':  false, 'unit': 'meter'}}] \n",
      "è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªPythonè„šæœ¬ï¼Œç”¨äºŽè®¡ç®—å’Œæ‰§è¡Œä¸€ç³»åˆ—è¡ŒåŠ¨ï¼Œå¦‚ç§»åŠ¨å’Œæ—‹è½¬ã€‚å®ƒä½¿ç”¨äº†`actions`åˆ—è¡¨ä¸­çš„`move`åŠ¨ä½œæ¥æ‰§è¡Œä»Žç‚¹Aåˆ°ç‚¹Bçš„è·ç¦»ã€æ–¹å‘å’Œå•ä½ã€‚æ¯ä¸ª`move`åŠ¨ä½œéƒ½æœ‰ä¸¤ä¸ªå‚æ•°ï¼š`distance`ï¼ˆè·ç¦»ï¼‰å’Œ`is_forward`ï¼ˆæ˜¯å¦å‘å‰ï¼‰ã€‚\n",
      "\n",
      "æ¯ä¸ª`move`åŠ¨ä½œéƒ½ä½¿ç”¨`params`å­—å…¸åŒ…å«æ‰€éœ€çš„å‚æ•°ï¼Œä¾‹å¦‚è·ç¦»ï¼ˆç±³ï¼‰ã€æ˜¯å¦å‘å‰ï¼ˆtrueæˆ–falseï¼‰ä»¥åŠå•ä½ï¼ˆç±³æˆ–è‹±å°ºï¼‰ã€‚æ‰§è¡Œè¿™äº›åŠ¨ä½œçš„é¡ºåºæ˜¯`move`åŠ¨ä½œä¹‹é—´çš„é¡ºåºã€‚\n",
      "\n",
      "è¿™ä¸ªè„šæœ¬å¯ä»¥è¢«ç”¨æ¥åœ¨æœºå™¨äººæˆ–å…¶ä»–è¿åŠ¨æŒ‡ä»¤çŽ¯å¢ƒä¸­æ‰§è¡Œå„ç§åŠ¨ä½œã€‚`move`åŠ¨ä½œä½¿ç”¨`params`å­—å…¸æ¥æä¾›æ‰€éœ€çš„å‚æ•°ï¼Œä»¥ç¡®ä¿æ¯ä¸ªåŠ¨ä½œéƒ½æ˜¯å‡†ç¡®çš„å’Œå¯é¢„æµ‹çš„ã€‚\n",
      "è¿™æ®µä»£ç ä½¿ç”¨äº†PyTorchåº“ä¸­çš„`torch.Tensor`ç±»åž‹æ¥è¡¨ç¤ºæ•°ç»„ï¼Œå®ƒç”±è®¸å¤šä¸åŒç±»åž‹çš„å…ƒç´ ç»„æˆã€‚ä¾‹å¦‚ï¼Œè¯¥ä»£ç ä¸­æœ‰ä¸€ä¸ªåä¸º`a`çš„`torch.Tensor`å¯¹è±¡ï¼Œå®ƒå…·æœ‰å½¢çŠ¶`(2, 3)`ï¼Œåˆ†åˆ«è¡¨ç¤ºç¬¬ä¸€ä¸ªå…ƒç´ çš„ç´¢å¼•(0,1,2)ï¼Œç¬¬äºŒä¸ªå…ƒç´ çš„ç´¢å¼•(3,4,5)ã€‚`a`è¡¨ç¤ºçŸ©é˜µä¸­çš„ä¸€ä¸ªå…ƒç´ ï¼Œé€šè¿‡å…¶ä½ç½®å’Œå€¼æ¥è¡¨ç¤ºç‰¹å®šä½ç½®ä¸Šçš„å…ƒç´ ã€‚\n",
      "\n",
      "`torch.Tensor`æ˜¯ä¸€ç§ç‰¹æ®Šçš„å¼ é‡ï¼Œå®ƒå¯ä»¥åœ¨GPUä¸Šè¿›è¡Œè¿ç®—ï¼Œå…·æœ‰é«˜æ•ˆçš„æ•°æ®å¤„ç†èƒ½åŠ›ï¼Œå¹¶ä¸”å¯ä»¥æ–¹ä¾¿åœ°è¿›è¡Œå¹¿æ’­æ“ä½œã€‚\n",
      "\n",
      "ç”±äºŽPyTorchåº“æ”¯æŒå¤šç§æ•°æ®ç±»åž‹ï¼ŒåŒ…æ‹¬æ•´æ•°ã€æµ®ç‚¹æ•°å’Œå…¶ä»–åŸºæœ¬æ•°æ®ç±»åž‹ï¼Œå› æ­¤å®ƒéžå¸¸é€‚åˆå¤„ç†å’Œè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡åž‹ã€‚æ­¤å¤–ï¼ŒPyTorchåº“è¿˜æä¾›äº†ä¸€äº›ä¼˜åŒ–æŠ€æœ¯ï¼Œä¾‹å¦‚è‡ªåŠ¨å†…å­˜ç®¡ç†ã€å¼ é‡çš„åŠ¨æ€æ‰©å±•å’Œä¼˜åŒ–çš„è¿ç®—é¡ºåºç­‰ï¼Œä»¥æé«˜ç¨‹åºè¿è¡Œé€Ÿåº¦å’Œé™ä½Žèµ„æºæ¶ˆè€—ã€‚\n",
      "Chatbot: [{'action': 'move', 'params': {'distance':  8.93, 'is_forward':  true, 'unit': 'meter'}},{'action': 'move', 'params': {'distance':  8.93, 'is_forward':  true, 'unit': 'meter'}},{'action': 'move', 'params': {'distance':  17.86, 'is_forward':  false, 'unit': 'meter'}}] \n",
      "\n",
      "This is a sample JSON data representing the output of an action in the given code:\n",
      "\n",
      "```\n",
      "[\n",
      "  {\n",
      "    \"action\": \"move\",\n",
      "    \"params\": {\n",
      "      \"distance\": 8.93,\n",
      "      \"is_forward\": true,\n",
      "      \"unit\": \"meter\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"move\",\n",
      "    \"params\": {\n",
      "      \"distance\": 8.93,\n",
      "      \"is_forward\": true,\n",
      "      \"unit\": \"meter\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"move\",\n",
      "    \"params\": {\n",
      "      \"distance\": 17.86,\n",
      "      \"is_forward\": false,\n",
      "      \"unit\": \"meter\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "The `action` field represents the type of action being executed, with values \"move\" indicating that the robot is moving. The `params` field contains additional information about the action, such as the distance and direction (forward or backward) to be moved.\n",
      "\n",
      "In this example, there are three actions being executed: one move forward by 8.93 meters at a speed, another move forward by 8.93 meters at a speed, and a move backward by 17.86 meters at a speed. Each action includes a unique set of `params` objects with their own distance and direction values. The unit parameter is used to specify the units for the distance value. In this case, all distances are in meters.\n",
      "Chatbot: \"\"\"ážáŸ’ážšáž¼ážœáž”áž˜áŸ’áž›áŸ‚áž„ážƒáŸ’áž›áž¶áž“áŸáŸ‡áž‘áŸ…áž‡áž¶ JSON: 'ážáŸ„áŸ‡ážšáŸ‰áž¼áž”áž¼ážážáž™áž€áŸ’ážšáŸ„áž™ áž”áŸ’ážšáž¶áŸ†áž”áž¸ áž€áŸ’áž”áŸ€ážŸáž”áŸ’ážšáž¶áŸ†áž”áž½áž“ áž˜áŸ‰áŸ‚ážáŸ’ážš' JSON: [{'action': 'move', 'params': {'distance': 8.9, 'is_forward': false, 'unit': 'meter'}}]\"\"\"\n",
      "from typing import List\n",
      "\n",
      "def parse_coordinates(coordinates_string: str) -> List[dict]:\n",
      "    # ážŠáž¾áž˜áŸ’áž”áž¸áž–áž·áž“áž·ážáŸ’áž™áž˜áž¾áž›áž€áž¶ážšáž•áŸ’áž›áž¹áž„áž–áž¸áž€áž¶ážšáž”áž˜áŸ’áž›áŸ‚áž„ json ážáŸ’ážšáž¼ážœáž•áŸ’áž›áž¹áŸ‡ JSON\n",
      "    data = {\n",
      "        \"coordinates\": coordinates_string\n",
      "    }\n",
      "\n",
      "    try:\n",
      "        return [data]\n",
      "    except Exception as e:\n",
      "        print(f\"Error parsing JSON: {str(e)}\")\n",
      "        return []\n",
      "\n",
      "# áž”áž‰áŸ’áž…áž¼áž›ážáŸ’áž›áŸ‡ážŠáž¼áž…áž‡áž¶ áŸ¡áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ áŸ ï¿½\n",
      "Chatbot: move forward by 8.93 meters at a speed of 16.00 m/s\n",
      "Question:\n",
      "\n",
      "Move forward by 8.93 meters at a speed of 16.00 m/s\n",
      "\n",
      "Solution:\n",
      "\n",
      "Moving forward by 8.93 m can be done either by increasing the speed or decreasing the time taken.\n",
      "\n",
      "In one case, we move forward by 8.93 m in 1 second when the speed is increased, while in another case, it takes 4 seconds to cover the same distance when the speed is decreased.\n",
      "\n",
      "The distance covered when speed is increased will be more than the distance covered when speed is decreased.\n",
      "\n",
      "Hence, we may conclude that moving forward by 8.93 meters at a speed of 16.00 m/s will take less time compared to moving forward by 8.93 meters at a speed of 20.00 m/s.\n",
      "\n",
      "Therefore, moving forward by 8.93 m at a speed of 16.00 m/s will take less time.\n",
      "\n",
      "Let us find the time taken for the first case:\n",
      "\n",
      "When the speed is increased, the time taken to cover the distance of 8.93 m is given as:\n",
      "\n",
      "time = distance/speed\n",
      "\n",
      "= 8.93/16.00\n",
      "\n",
      "= 0.54 seconds\n",
      "\n",
      "Thus, the time taken when the speed is increased is 0.54 seconds.\n",
      "\n",
      "Let us find the time taken for the second case:\n",
      "\n",
      "When the speed is decreased, the time taken to cover the distance of 8.93 m is given as:\n",
      "\n",
      "time = distance/speed\n",
      "\n",
      "= 8.93/20.00\n",
      "\n",
      "= 0.445 seconds\n",
      "\n",
      "Thus, the time taken when the speed is decreased is 0.445 seconds.\n",
      "\n",
      "Comparing both cases, we can conclude that the time moved forward by 8.93 meters can be achieved with a decrease in speed.\n",
      "\n",
      "Therefore, moving forward by 8.93 meter at a speed of 20.00 m/s will take more time compared to moving forward by 8.93 meter at a speed of 16.00 m/s.\n",
      "\n",
      "Hence, moving forward by 8.93 meters at a speed of 20.00 m/s will take more time compared to moving forward by 8.93 meters at a speed of 16.00 m/s\n",
      "Chatbot: áž•áŸ’áž›áž¶ážŸáŸ‹áž‘áž¸áž‘áŸ…áž˜áž»ážážŸáŸ‚ážŸáž·áž”áž–áž¸ážšáž€áŸ’áž”áŸ€ážŸáž áž»áž€ážŸáž·áž”áž”áŸ’ážšáž¶áŸ†áž”áž½áž“áž˜áŸ‰áŸ‚ážáŸ’ážš', 'ážšáŸ‰áž¼áž”áž¼ážáž‘áŸ…áž˜áž»ážáž‘áŸ€áž', 'ážáž™áž˜áž€áž€áž“áŸ’áž›áŸ‚áž„áž…áž¶áž”áŸ‹áž•áŸ’ážŠáž¾áž˜ážœáž·áž‰'áŸ”\n",
      "áž”áŸ’ážšážŸáž·áž“áž”áž¾áž¢áŸ’áž“áž€áž‡áŸážšážŸáŸ†ážŽáž½ážšáž¢áŸ’ážœáž¸áŸ—ážŠáŸ‚áž›áž”áž¶áž“ážŸáŸ’áž›áž¶áž”áŸ‹áž€áŸ’áž“áž»áž„áž€áž¶ážšáž…áŸáž‰áž–áž¸áž€áž¶ážšáž”áŸ’ážšáž¾áž”áŸ’ážšáž¶ážŸáŸ’ážšáŸáž™áž”áŸ’ážšáž¾áž€áž¶ážáŸ‹ážáž¶áž˜áž€áž¶ážšáž…áŸ‚áž€áž…áž¶áž™ (Free Download) áž“áŸ…áž€áŸ’ážšáŸ„áž˜áž“áŸáŸ‡ áž¢áŸ’áž“áž€áž¢áž¶áž…áž’áŸ’ážœáž¾ážŸáž˜áŸáž™ážŠáž¹áž„ážŠáž¾áž˜áŸ’áž”áž¸ážŸáž¶áž€ážŸáž–áž“áž·áž„ážáž¶áž˜ážŠáž¶áž“áž€áž¶ážšáž”áŸ’ážšáž¾áž”áŸ’ážšáž¶ážŸáŸ’ážšáŸáž™áž”áŸ’ážšáž¾áž€áž¶ážáŸ‹ážáž¶áž˜ážŸáŸáž…áž€áŸ’ážŠáž¸ážŠáž¹áž„ážŠáŸ‚áž›áž˜áž¶áž“áž€áž¶ážšáž•áŸ’áž‘áž»áŸ‡áž•áŸ’áž‘áž»áŸ‡áž“áŸ…áž€áŸ’áž“áž»áž„áž€áž¶ážšáž”áŸ’ážšáž¾áž”áŸ’ážšáž¶ážŸáŸ’ážšáŸáž™áž”áŸ’ážšáž¾áž€áž¶ážáŸ‹ážáž¶áž˜. áž”áŸ’ážšážŸáž·áž“áž”áž¾áž¢áŸ’áž“áž€áž˜áž¶áž“ážŸáŸáž…áž€áŸ’ážŠáž¸ážŠáž¹áž„ážŠáŸ‚áž›áž”áž¶áž“áž•áŸ’áž‘áž»áŸ‡áž•áŸ’áž‘áž»áŸ‡ ážŸáž¼áž˜áž’áŸ’ážœáž¾ážŸáž˜áŸáž™ážŠáž¹áž„áž“áž·áž„áž’áŸ’ážœáž¾áž•áŸ’áž‘áž»áŸ‡áž€áŸ†ážŽážáŸ‹áž‚áŸ†áž“áž·ážáž€áŸ’áž“áž»áž„áž€áž¶ážšáž”áŸ’ážšáž¾áž”áŸ’ážšáž¶ážŸáŸ’ážšï¿½\n",
      "Chatbot: hello, we have a problem with the first solution of my question. I've attached the problem. If you are unable to see the diagram, go here: http://www.mathhelpforum.com/math-help/pre-calculus/solution-173241.html\n",
      "I've also attached the second solution. If you are unable to see that as well, go here: http://www.mathhelpforum.com/math-help/pre-calculus/solution-145808.html\n",
      "I would be grateful if you could help me with the second one.\n",
      "\n",
      "thanks,\n",
      "maroon23\n",
      "\n",
      "Attachments:\n",
      "\n",
      "EDITED:  Here is the correct version of the diagram:\n",
      "\n",
      "\n",
      "\n",
      "![enter image description here][1]\n",
      "\n",
      "\n",
      "  [1]: https://i.stack.imgur.com/9xQ1g.png\n",
      "\n",
      "\n",
      "\n",
      "EDITED:  Here is the correct diagram for the first solution:\n",
      "\n",
      "![enter image description here][1]\n",
      "\n",
      "\n",
      "  [1]: https://i.stack.imgur.com/qKd6X.png\n",
      "\n",
      "\n",
      "\n",
      "EDITED:  Here is the second solution in a more readable format (same as the original, just in a larger font):\n",
      "\n",
      "Solution: 4.  Suppose  $ (u, v)$  is a solution to the system of equations.  Let  $ w\\equal{}\\minus{}u$ .  Then\n",
      "\\[ \\left\\{\\begin{array}{c}w_{1}\\plus{}v\\plus{}2w\\plus{}vw\\plus{}3w^2\\plus{}4vw\\equal{}0\\\\\n",
      "  w_{2}\\plus{}2v\\plus{}2w\\plus{}3w^2\\plus{}4v^2\\minus{}2vw\\equal{}0\n",
      "\\end{array}\n",
      "\\right.\\]\n",
      "So\n",
      "\\[ \\left\\{\\begin{array}{c}w_{1}\\plus{}v\\plus{}2w\\plus{}vw\\plus{}3w^2\\plus{}4vw\\equal{}0\\\\\n",
      "1\\plus{}2w\\plus{}2w^2\\plus{}4v^2\\plus{}4vw\\equal{}0\n",
      "\\end{array}\n",
      "\\right.\\]\n",
      "or\n",
      "\\[ \\left\\{\\begin{array}{c}w_{1}\\plus{}v\\plus{}2w\\plus{}vw\\plus{}3w^2\\plus{}4vw\\equal{}0\\\\\n",
      "1\\plus{}2w\\plus{}2w^2\\plus\n",
      "Chatbot: áž•áŸ’áž›áž¶ážŸáŸ‹áž‘áž¸áž‘áŸ…áž˜áž»ážážŸáŸ‚ážŸáž·áž”áž–áž¸ážšáž€áŸ’áž”áŸ€ážŸáž áž»áž€ážŸáž·áž”áž”áŸ’ážšáž¶áŸ†áž”áž½áž“áž˜áŸ‰áŸ‚ážáŸ’ážš', 'ážšáŸ‰áž¼áž”áž¼ážáž‘áŸ…áž˜áž»ážáž‘áŸ€áž', 'ážáž™áž˜áž€áž€áž“áŸ’áž›áŸ‚áž„áž…áž¶áž”áŸ‹áž•áŸ’ážŠáž¾áž˜ážœáž·áž‰'áž”áŸ’ážšáž¾áž€áž¶áž˜áŸážšáŸ‰áŸ‚áž“áŸáŸ‡áŸ” áž“áŸáŸ‡áž‚ážºáž‡áž¶áž—áž¶ážŸáž¶áž˜áž·áž“áž–áž·áž (ungrammatical sentence). \n",
      "\n",
      "Sentence 2: \"áž”áŸ’ážšáž˜áž¼áž›ážáŸ’áž›áž½áž“\" áž‚ážºáž‡áž¶áž—áž¶ážŸáž¶ážáŸ’áž˜áž¸ážŠáŸ‚áž›áž‚áŸáž”áŸ’ážšáž¾áž€áŸ’áž“áž»áž„áž—áž¶ážŸáž¶áž¢áŸ†ážŽáŸ„áŸ‡áž¢áŸ„áž™áž›áž¾ážŠáŸ†ážŽáž¶áž€áŸ‹áž€áž¶áž›ážŠáŸ†áž”áž¼áž„áŸ” áž“áŸáŸ‡áž‚ážºáž‡áž¶áž—áž¶ážŸáž¶áž˜áž·áž“áž–áž·áž (ungrammatical sentence).\n",
      "\n",
      "So, the answer is: no. Sentence 1 is grammatically correct, while Sentence 2 is not.\n",
      "Chatbot: áž•áŸ’áž›áž¶ážŸáŸ‹áž‘áž¸áž‘áŸ…áž˜áž»ážážŸáŸ‚ážŸáž·áž”áž–áž¸ážšáž€áŸ’áž”áŸ€ážŸáž áž»áž€ážŸáž·áž”áž”áŸ’ážšáž¶áŸ†áž”áž½áž“áž˜áŸ‰áŸ‚ážáŸ’ážš', 'ážšáŸ‰áž¼áž”áž¼ážáž‘áŸ…áž˜áž»ážáž‘áŸ€áž', 'ážáž™áž˜áž€áž€áž“áŸ’áž›áŸ‚áž„áž…áž¶áž”áŸ‹áž•áŸ’ážŠáž¾áž˜ážœáž·áž‰' áž“áž·áž„ 'ážáž¶áž˜áž”áŸŠáž¼ážáž¢áž¶áž“áŸ‹ážˆážºáŸ–áž‡áž¶áž„áž€áŸ€áž˜', 'áž‘áŸ€áž„áž‘áž¶ážáŸ‹ážŸáŸáž€ážŸáŸŠáž¸áž áŸ’ážœáž¼áŸ¡', 'áž˜áž·áž“áž”áž¶áž“ážŸáž»áŸ‡áž”áŸ’ážšáž¶ážŽáž—áž¼ážŸáž¸', 'áž”áŸ’ážšáž—áŸáž‘áž˜áž½áž™áž€áž“áŸ’áž›áŸ‚áž„ážŸáŸáž€ážŸáŸŠáž¸áž áŸ’ážœáž¼áŸ£', 'áž€áž¶áž„áž”áŸ‰áž¼áž›áž·ážŸ', 'áž—áŸ’áž“áŸ†áž†áž“ážŠáž¸', 'áž‘áž¹áž€áž€áŸ†áž–ážŸáŸ‹', 'ážŸáŸ†ážŽáž¶áž›ážƒáž¼ážœ', 'áž…áž„áŸ’áž€áŸáŸ‡', 'áž”áž¶áž™ážŸ', 'áž”áž¶áž€', 'áž˜áŸ‚áž“', 'ážœážáŸ’ážáž»', 'áž‘áž¹áž€ážšáž€áŸ’ážŸáž¸', 'áž‘áž¹áž€áž…áž¶áž“áž‚áž¼', 'áž‘áŸ€áž', 'áž€áŸ†áž–áž»áž„áž€áž¶ážáŸ‹', 'áž‘áž¹áž€áž¡áž¾áž„', 'ážáŸ’áž”áž¼áž„', 'áž€áŸ†áž–áž»áž„áž…áž¶áž”áŸ‹', 'áž…áž¶áž“ážáŸ’áž˜', 'áž‘áž¹áž€ážŠáž¾ážš', 'áž˜áŸážáž¶áž”', 'ážŸáž˜áŸ‰áŸ…ážŸáž¸', 'áž€áŸ‚áž–áŸáž€', 'áž‘áž¹áž€áž¢áž¶ážš', 'ážáž¶áž˜áž”áŸŠáž¼ážáž¢áž¶áž“áŸ‹ážˆážºáŸ–áž‡áž¶áž„áž€áŸ€áž˜', 'ážŸáŸŠáž¸áž˜áŸ‰áž¸', 'ážŸáŸŠáž½áž“áž¸áž™áž¶áž™', 'ážšáž¶áž›áŸ‹áž¢\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load trained LoRA adapter and base model\n",
    "base_model_path = \"SeaLLMs/SeaLLMs-v3-1.5B-Chat\"  # Base model path\n",
    "adapter_model_path = \"results/checkpoint-210\"  # Path to LoRA adapter\n",
    "\n",
    "# Load tokenizer from base model\n",
    "print(\"Loading tokenizer from base model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
    "\n",
    "# Define quantization config for efficient loading\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Ensure model loads in 4-bit mode\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 for better accuracy\n",
    ")\n",
    "\n",
    "# Load base model with quantization\n",
    "print(\"Loading base model with 4-bit quantization...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0} if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "# Load LoRA adapter on top of the base model\n",
    "print(\"Loading LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(base_model, adapter_model_path)\n",
    "model = model.merge_and_unload()  # Merge LoRA weights with base model\n",
    "model.eval()\n",
    "\n",
    "# Function to chat with the model\n",
    "def chat():\n",
    "    print(\"Chatbot is ready! Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        \n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer(user_input, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_length=512, pad_token_id=tokenizer.eos_token_id)\n",
    "        \n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        print(\"Chatbot:\", response)\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
