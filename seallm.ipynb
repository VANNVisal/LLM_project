{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4744e782-5c88-449a-9d6d-9ec053d0ff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, TrainerCallback, AutoConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf9248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load datasets\n",
    "train_dataset = load_dataset('json', data_files=r'C:\\Users\\BNC\\Documents\\ITC-Internship\\LLM\\LLM-Model\\visal\\split_data\\train.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files=r'C:\\Users\\BNC\\Documents\\ITC-Internship\\LLM\\LLM-Model\\visal\\split_data\\valid.jsonl', split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91366431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load and quantize model\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "#model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#model_id = \"cognitivecomputations/dolphin-2.6-mistral-7b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82d1c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvannvisal1012\u001b[0m (\u001b[33mvannvisal1012-institute-of-tecnology-of-cambodia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\BNC\\Downloads\\Telegram Desktop\\GPTForRobotics-dev\\GPTForRobotics-dev\\finetuning_model\\wandb\\run-20250219_141533-x7uxb2ge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune/runs/x7uxb2ge' target=\"_blank\">celestial-galaxy-6</a></strong> to <a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune' target=\"_blank\">https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune/runs/x7uxb2ge' target=\"_blank\">https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune/runs/x7uxb2ge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb_config = {\"model\": model_id}\n",
    "wandb.init(project=\"fine-tune\", config=wandb_config)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69840b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12456\\331468681.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             return model_class.from_pretrained(\n\u001b[0m\u001b[0;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3657\u001b[1;33m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[0;32m   3658\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3659\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mbnb_multibackend_is_enabled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_bitsandbytes_multi_backend_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mvalidate_bnb_backend_availability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_exception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"from_tf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"from_flax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\integrations\\bitsandbytes.py\u001b[0m in \u001b[0;36mvalidate_bnb_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_bitsandbytes_multi_backend_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_validate_bnb_multi_backend_availability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_validate_bnb_cuda_backend_availability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\integrations\\bitsandbytes.py\u001b[0m in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "source": [
    "\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, quantization_config=bnb_config, device_map='auto', use_cache=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613432f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Lora (fine-tuning) Config\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# constructs prompt the way model understands\n",
    "def create_prompt_universal(examples):\n",
    "    output_text = []\n",
    "    for i in range(len(examples[\"input\"])):\n",
    "        input_text = examples[\"input\"][i]\n",
    "        response = examples[\"output\"][i]\n",
    "\n",
    "        chat_template = [{\"role\": \"user\", \"content\": input_text}, {\"role\": \"assistant\", \"content\": response}]\n",
    "        prompt = tokenizer.apply_chat_template(chat_template, tokenize=False)\n",
    "\n",
    "        output_text.append(prompt)\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6021ee-da41-471f-9285-038cf5dcd48f",
   "metadata": {},
   "source": [
    "### Matric Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b102ad-b934-4f72-987a-a74dbabc99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcddaee3-e462-4550-9646-b62d976a8211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmenghor/.local/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 256\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"zephyr_instruct_generation\",\n",
    "    #max_steps=200,\n",
    "    max_steps=1200,\n",
    "    #per_device_train_batch_size=4,\n",
    "    per_device_train_batch_size=5, #scale the rest of the batch in the same size 131 batch, each with 5 sample.\n",
    "    warmup_steps=0,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    #learning_rate=1e-4,\n",
    "    learning_rate=1e-5,\n",
    "    bf16=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"wandb\",\n",
    "    #push_to_hub=True,\n",
    "    \n",
    ")\n",
    "class LossTrackerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.training_loss_values = []\n",
    "        self.eval_loss_values = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if \"loss\" in logs:\n",
    "            self.training_loss_values.append(logs[\"loss\"])\n",
    "        if \"eval_loss\" in logs:\n",
    "            self.eval_loss_values.append(logs[\"eval_loss\"])\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        plt.plot(self.training_loss_values, label=\"Training Loss\")\n",
    "        plt.plot(self.eval_loss_values, label=\"Evaluation Loss\")\n",
    "        plt.xlabel(\"Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Learning Curve\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "loss_tracker = LossTrackerCallback()\n",
    "    \n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    formatting_func=create_prompt_universal,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    callbacks=[loss_tracker],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04ee534-aef5-4044-9b3a-5c541ecd90d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 1:16:56, Epoch 10/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.795100</td>\n",
       "      <td>1.753028</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.706100</td>\n",
       "      <td>1.645983</td>\n",
       "      <td>0.598744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>1.551861</td>\n",
       "      <td>0.611815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.512200</td>\n",
       "      <td>1.452057</td>\n",
       "      <td>0.633262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.387000</td>\n",
       "      <td>1.349861</td>\n",
       "      <td>0.653293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.303600</td>\n",
       "      <td>1.249939</td>\n",
       "      <td>0.672420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.192100</td>\n",
       "      <td>1.149514</td>\n",
       "      <td>0.686849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.090200</td>\n",
       "      <td>1.057098</td>\n",
       "      <td>0.710446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.011400</td>\n",
       "      <td>0.980243</td>\n",
       "      <td>0.716953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.934500</td>\n",
       "      <td>0.911116</td>\n",
       "      <td>0.722612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.872800</td>\n",
       "      <td>0.838868</td>\n",
       "      <td>0.729912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.759412</td>\n",
       "      <td>0.735061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.695975</td>\n",
       "      <td>0.743889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.662400</td>\n",
       "      <td>0.657022</td>\n",
       "      <td>0.752377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.634700</td>\n",
       "      <td>0.629530</td>\n",
       "      <td>0.757073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.758997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.598300</td>\n",
       "      <td>0.588054</td>\n",
       "      <td>0.761770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.568269</td>\n",
       "      <td>0.764147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>0.548210</td>\n",
       "      <td>0.766410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.527193</td>\n",
       "      <td>0.768108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.504020</td>\n",
       "      <td>0.770032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.467800</td>\n",
       "      <td>0.480041</td>\n",
       "      <td>0.771446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.452552</td>\n",
       "      <td>0.773993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.425135</td>\n",
       "      <td>0.776879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.402012</td>\n",
       "      <td>0.779086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.382752</td>\n",
       "      <td>0.780217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.782254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.355100</td>\n",
       "      <td>0.352506</td>\n",
       "      <td>0.784065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.342353</td>\n",
       "      <td>0.784631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.332928</td>\n",
       "      <td>0.785593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.323252</td>\n",
       "      <td>0.786612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>0.316844</td>\n",
       "      <td>0.787404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.312451</td>\n",
       "      <td>0.788253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.307761</td>\n",
       "      <td>0.788875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.303514</td>\n",
       "      <td>0.789328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.299261</td>\n",
       "      <td>0.789667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.295923</td>\n",
       "      <td>0.789554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.275100</td>\n",
       "      <td>0.291622</td>\n",
       "      <td>0.790686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.286700</td>\n",
       "      <td>0.289207</td>\n",
       "      <td>0.790742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.285973</td>\n",
       "      <td>0.791308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>0.283060</td>\n",
       "      <td>0.791478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.280672</td>\n",
       "      <td>0.791478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>0.279689</td>\n",
       "      <td>0.791308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.264100</td>\n",
       "      <td>0.275607</td>\n",
       "      <td>0.793345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.275625</td>\n",
       "      <td>0.792610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.274102</td>\n",
       "      <td>0.792610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.271501</td>\n",
       "      <td>0.793176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.269809</td>\n",
       "      <td>0.793685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.269064</td>\n",
       "      <td>0.794024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.269286</td>\n",
       "      <td>0.793176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.267270</td>\n",
       "      <td>0.794024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>0.265145</td>\n",
       "      <td>0.793968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.264483</td>\n",
       "      <td>0.793459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.262268</td>\n",
       "      <td>0.794817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>0.260703</td>\n",
       "      <td>0.795043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.260697</td>\n",
       "      <td>0.794138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.261607</td>\n",
       "      <td>0.793798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.259961</td>\n",
       "      <td>0.794534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.258597</td>\n",
       "      <td>0.795100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.256593</td>\n",
       "      <td>0.795722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.241200</td>\n",
       "      <td>0.256385</td>\n",
       "      <td>0.795043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.255544</td>\n",
       "      <td>0.795100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.254623</td>\n",
       "      <td>0.794930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.256238</td>\n",
       "      <td>0.794760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.253509</td>\n",
       "      <td>0.795552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.253253</td>\n",
       "      <td>0.795609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.252675</td>\n",
       "      <td>0.794986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.252984</td>\n",
       "      <td>0.794873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.227200</td>\n",
       "      <td>0.253841</td>\n",
       "      <td>0.794873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.252693</td>\n",
       "      <td>0.794760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.249617</td>\n",
       "      <td>0.795156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.249573</td>\n",
       "      <td>0.795213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>0.249562</td>\n",
       "      <td>0.795439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.250479</td>\n",
       "      <td>0.795496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.248864</td>\n",
       "      <td>0.795779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>0.251364</td>\n",
       "      <td>0.794307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.249346</td>\n",
       "      <td>0.794817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.249293</td>\n",
       "      <td>0.794703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.211300</td>\n",
       "      <td>0.250253</td>\n",
       "      <td>0.792723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.248510</td>\n",
       "      <td>0.793685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.247860</td>\n",
       "      <td>0.795100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.246256</td>\n",
       "      <td>0.795326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.247051</td>\n",
       "      <td>0.794081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.245152</td>\n",
       "      <td>0.794760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.245351</td>\n",
       "      <td>0.795100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>0.247373</td>\n",
       "      <td>0.795043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.246048</td>\n",
       "      <td>0.794590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.247462</td>\n",
       "      <td>0.794930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.246873</td>\n",
       "      <td>0.795326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.247314</td>\n",
       "      <td>0.794873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.246307</td>\n",
       "      <td>0.794138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.244854</td>\n",
       "      <td>0.794873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.207800</td>\n",
       "      <td>0.246209</td>\n",
       "      <td>0.795496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>0.245538</td>\n",
       "      <td>0.795722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.245031</td>\n",
       "      <td>0.796231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>0.243240</td>\n",
       "      <td>0.795156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.242163</td>\n",
       "      <td>0.795269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.242703</td>\n",
       "      <td>0.795665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.243688</td>\n",
       "      <td>0.794930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.795496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.242935</td>\n",
       "      <td>0.795496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.244075</td>\n",
       "      <td>0.795213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>0.248195</td>\n",
       "      <td>0.796005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.251111</td>\n",
       "      <td>0.795383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.210200</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>0.795552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.241327</td>\n",
       "      <td>0.795383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.243385</td>\n",
       "      <td>0.794024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.241763</td>\n",
       "      <td>0.795722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.242275</td>\n",
       "      <td>0.795213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.795269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.247304</td>\n",
       "      <td>0.794251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.195600</td>\n",
       "      <td>0.245145</td>\n",
       "      <td>0.794534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.244082</td>\n",
       "      <td>0.794873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>0.795213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.243892</td>\n",
       "      <td>0.795156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>0.242439</td>\n",
       "      <td>0.795496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.245832</td>\n",
       "      <td>0.795269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.246497</td>\n",
       "      <td>0.794421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.242342</td>\n",
       "      <td>0.795779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.243725</td>\n",
       "      <td>0.795609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 6847a6a3-4013-4fba-a381-ae229e7e56b0)') - silently ignoring the lookup for the file config.json in HuggingFaceH4/zephyr-7b-beta.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in HuggingFaceH4/zephyr-7b-beta - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: a775bebc-43ec-4168-b693-aaa13084463b)') - silently ignoring the lookup for the file config.json in HuggingFaceH4/zephyr-7b-beta.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in HuggingFaceH4/zephyr-7b-beta - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/tmenghor/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1200, training_loss=0.37695309857527415, metrics={'train_runtime': 4619.7508, 'train_samples_per_second': 1.299, 'train_steps_per_second': 0.26, 'total_flos': 2.2153272322105344e+16, 'train_loss': 0.37695309857527415, 'epoch': 10.909090909090908})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386cded5-bc75-4175-bc6e-64e884722d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeViVdf7/8ed9DnDYQVwQFRR3zFDTzDTXpkzLxpZR03LJymrKFLOyHGuaRquxMrNsZkr92Zg5rmOllma5tHxdErVccEFBRXFl37l/f4BnhhQFBG4OvB7Xda7p3Ode3ge9hpef1TBN00RERESkmrBZXYCIiIhIeVK4ERERkWpF4UZERESqFYUbERERqVYUbkRERKRaUbgRERGRakXhRkRERKoVhRsRERGpVhRuREREpFpRuBGppubNm4dhGGzbts3qUkrtu+++wzAMvvvuO8tqOHz4ME899RQtW7bEy8sLb29vrrvuOiZPnszx48ctq0tErs7N6gJERH7rhhtu4Mcff6RNmzaWPP+LL75gyJAh1KlTh6eeeooOHTpgGAa7d+9mzpw5fPnll+zYscOS2kTk6hRuRKTCpaen4+3tXeLz/f396dKlSwVWVLzY2FiGDBlCy5Yt+fbbbwkICHB+1qdPH8aOHcvy5cvL5Vk5OTkYhoGbm/6vWKQ8qVtKpIZLTk7m2WefJTw8HA8PDxo2bMi4ceNIS0srct77779Pjx49qFevHj4+Plx//fW8+eab5OTkFDmvV69etG3blo0bN9K1a1e8vb15+OGHAWjSpAl33XUXa9as4YYbbsDLy4vWrVszZ86cIve4XLfUyJEj8fX15eDBg/Tv3x9fX19CQ0OZMGECWVlZRa4/duwY999/P35+fgQGBjJs2DC2bt2KYRjMmzfvij+Pt99+m7S0ND744IMiweYiwzC49957ne+bNGnCyJEjLzmvV69e9OrV65Lv9MknnzBhwgQaNmyIw+Hg119/xTAMPv7440vusXr1agzDYOXKlc5jBw4cYOjQodSrVw+Hw0FERATvv//+Fb+TSE2jfy6I1GDp6en07NmTY8eO8eKLLxIZGcmvv/7KlClT2L17N+vWrcMwDAAOHTrE0KFDnSFo586d/PWvf2Xfvn2XhJOEhAQefPBBnnvuOaZOnYrN9t9/R+3cuZMJEybwwgsvEBwczEcffcTo0aNp3rw5PXr0uGK9OTk53H333YwePZoJEyawceNG/vKXvxAQEMCUKVMASEtLo3fv3pw7d4433niD5s2bs2bNGgYPHlyin8nXX39NcHBwhbUcTZo0iZtvvpkPP/wQm81GaGgoHTp0YO7cuYwePbrIufPmzaNevXr0798fgD179tC1a1fCwsJ46623qF+/Pl999RVjx47lzJkzvPzyyxVSs4jLMUWkWpo7d64JmFu3bi32nGnTppk2m+2Sc5YsWWIC5qpVqy57XV5enpmTk2POnz/ftNvt5rlz55yf9ezZ0wTMb7755pLrGjdubHp6eppHjx51HsvIyDCDgoLMMWPGOI99++23JmB+++23zmMjRowwAfPf//53kXv279/fbNWqlfP9+++/bwLm6tWri5w3ZswYEzDnzp1b7M/DNE3T09PT7NKlyxXP+e13GjFixCXHe/bsafbs2fOS79SjR49Lzp05c6YJmPv373ceO3funOlwOMwJEyY4j/Xt29ds1KiRmZSUVOT6p556yvT09Czy5yBSk6lbSqQG++KLL2jbti3t27cnNzfX+erbt+8l3UI7duzg7rvvpnbt2tjtdtzd3Rk+fDh5eXnExMQUuW+tWrXo06fPZZ/Zvn17wsLCnO89PT1p2bIlR48evWq9hmEwYMCAIsciIyOLXLthwwb8/Py44447ipz3wAMPXPX+leG+++675NiwYcNwOBxFuswWLlxIVlYWo0aNAiAzM5NvvvmGe+65B29v7yJ/Xv379yczM5Offvqpsr6GSJWmcCNSg506dYpdu3bh7u5e5OXn54dpmpw5cwaAuLg4unfvzvHjx3n33XfZtGkTW7dudY71yMjIKHLfkJCQYp9Zu3btS445HI5L7nE53t7eeHp6XnJtZmam8/3Zs2cJDg6+5NrLHbucsLAwYmNjS3RuWVzuZxMUFMTdd9/N/PnzycvLAwq6pDp37sx1110HFHyv3Nxc3nvvvUv+vC52W1388xKp6TTmRqQGq1OnDl5eXpeMmfnfzwFWrFhBWloay5Yto3Hjxs7Po6OjL3vdxXE6VqhduzZbtmy55PjJkydLdH3fvn157733+Omnn0o07sbT0/OSAc1QEDQu/vz+V3E/m1GjRrF48WLWrl1LWFgYW7duZfbs2c7Pa9Wqhd1u56GHHuKPf/zjZe8RHh5+1XpFagKFG5Ea7K677mLq1KnUrl37ir8YL/5CdjgczmOmafLPf/6zwmssrZ49e/Lvf/+b1atX069fP+fxzz77rETXjx8/njlz5vDkk09eMhUcCr73ihUruOeee4CC2VK7du0qck5MTAz79++/bLgpzu23307Dhg2ZO3cuYWFheHp6FulK8/b2pnfv3uzYsYPIyEg8PDxKfG+RmkbhRqSaW79+PUeOHLnkeP/+/Rk3bhxLly6lR48ejB8/nsjISPLz84mLi+Prr79mwoQJ3HTTTdx22214eHjwwAMP8Nxzz5GZmcns2bM5f/585X+hqxgxYgTvvPMODz74IK+99hrNmzdn9erVfPXVVwBFZm5dTnh4OJ999hmDBw+mffv2zkX8oGC20pw5czBN0xluHnroIR588EGefPJJ7rvvPo4ePcqbb75J3bp1S1W33W5n+PDhvP322/j7+3PvvfdeEqzeffddbrnlFrp3784TTzxBkyZNSElJ4eDBg3z++eesX7++VM8Uqa4UbkSqueeff/6yx2NjY2nSpAmbNm3i9ddf5x//+AexsbF4eXkRFhbG7373O5o0aQJA69atWbp0KZMnT+bee++ldu3aDB06lKioqCKtI1WBj48P69evZ9y4cTz33HMYhsHtt9/OBx98QP/+/QkMDLzqPe666y52797NW2+9xYcffkh8fDw2m43w8HDuuOMOnn76aee5Q4cO5cSJE3z44YfMnTuXtm3bMnv2bP785z+XuvZRo0Yxbdo0Tp8+7RxI/L/atGnDzz//zF/+8hcmT55MYmIigYGBtGjRwjnuRkTAME3TtLoIEZGKNnXqVCZPnkxcXByNGjWyuhwRqUBquRGRamfWrFlAQYtTTk4O69evZ+bMmTz44IMKNiI1gMKNiFQ73t7evPPOOxw5coSsrCzCwsJ4/vnnmTx5stWliUglULeUiIiIVCtaxE9ERESqFYUbERERqVYUbkRERKRaqXEDivPz8zlx4gR+fn6WLhEvIiIiJWeaJikpKTRo0OCqi3HWuHBz4sQJQkNDrS5DREREyiA+Pv6qSzrUuHDj5+cHFPxw/P39La5GRERESiI5OZnQ0FDn7/ErqXHh5mJXlL+/v8KNiIiIiynJkBINKBYREZFqReFGREREqhWFGxEREalWatyYGxERKZ28vDxycnKsLkNqAA8Pj6tO8y4JhRsREbks0zQ5efIkFy5csLoUqSFsNhvh4eF4eHhc030UbkRE5LIuBpt69erh7e2thU+lQl1cZDchIYGwsLBr+vumcCMiIpfIy8tzBpvatWtbXY7UEHXr1uXEiRPk5ubi7u5e5vtoQLGIiFzi4hgbb29viyuRmuRid1ReXt413UfhRkREiqWuKKlM5fX3zdJws3HjRgYMGECDBg0wDIMVK1Zc9ZoFCxbQrl07vL29CQkJYdSoUZw9e7YSqhURERFXYGm4SUtLo127dsyaNatE52/evJnhw4czevRofv31VxYvXszWrVt55JFHKrhSERER6NKlCy+88EKJz9+3bx+GYbBv374KrEp+y9IBxf369aNfv34lPv+nn36iSZMmjB07FoDw8HDGjBnDm2++WVElioiIC7lat8aIESOYN29eme+/atWqUk1TbtGiBQkJCdStW7fMzyyJffv2ERERwd69e2ndunWFPssVuNSYm65du3Ls2DFWrVqFaZqcOnWKJUuWcOeddxZ7TVZWFsnJyUVeFSU5M4c9Jyru/iIicmUJCQnO14wZM/D39y9y7N13373sdSVdpDAoKAhfX98S12O326lfvz52u73E18i1c7lws2DBAgYPHoyHhwf169cnMDCQ9957r9hrpk2bRkBAgPMVGhpaIbXtTUgm8pWvGfbRT5imWSHPEBGRK6tfv77zFRAQgGEYlxy72FW0bNkyunfvjsPhYMmSJZw6dYpBgwbRsGFDvL29adeuHUuXLi1y/992S9WvX5/p06czfPhwfH19adKkSZGWod92S61ZswbDMNiwYQMdOnTAx8eHHj16cOjQIec1pmkyZcoU6tSpQ0BAAI8//jhRUVF06dLlmn42M2fOdC6QFxERwaJFi4o886WXXiI0NBSHw0GjRo149tlnnZ/PmDGDZs2a4XA4CA4OZujQoddUS0VzqXCzZ88exo4dy5QpU9i+fTtr1qwhNjaWxx9/vNhrJk2aRFJSkvMVHx9fIbU1reuDu93gfHoOx85nVMgzRESsZJom6dm5lf6qqH8wPv/88zz77LPs27eP3r17k5GRQdeuXfnyyy/ZvXs3I0aMYPDgwURHR1/xPm+88Qbdu3cnOjqahx9+mEcffZTY2NgrXjN58mTee+89tmzZQnZ2No899pjzszlz5vDWW2/xzjvvsHXrVurUqcPHH398Td914cKFPPfcc7z44ov88ssvjBgxgqFDh/Ljjz8CBZN1Zs+ezccff8yBAwdYunQpbdq0AQrGuz733HO8/vrrxMTEsHr1arp27XpN9VQ0l1rEb9q0aXTr1o2JEycCEBkZiY+PD927d+e1114jJCTkkmscDgcOh6PCa3O42Wld35/dx5PYdSyJ0CCtDSEi1UtGTh5tpnxV6c/d82pfvD3K/9fVs88+y+9///six8aNG+f876ioKL788kuWLFlC+/bti73PwIEDefTRR4GC0PL222+zYcMGwsPDi73m9ddfp1u3bgA899xzDBo0iLy8POx2O++99x5PPPEEDz30EACvvfYaa9asKfP3BJg+fTqPPfaYs84XXniBH374genTp7N06VLi4uJo2LAht956K3a7nbCwMG666SYA4uLi8Pf3584778Tb25vGjRtzww03XFM9Fc2lWm7S09Mv2VDrYj9mVegKur5RAAC7jmsfFhGRqq5Tp05F3ufm5vLqq69y/fXXO8fWbNy4kbi4uCveJzIy0vnfNpuN4OBgEhMTS3xNSEgIeXl5zmVNYmJi6Ny5c5Hzf/u+tPbt2+cMUxd169aNvXv3AjBkyBDOnTtH06ZNGTNmDCtXrnQupNe/f3/q1q1LeHg4I0aMYOHChWRmZl5TPRXN0pab1NRUDh486HwfGxtLdHQ0QUFBhIWFMWnSJI4fP878+fMBGDBgAI8++iizZ8+mb9++JCQkMG7cODp37kyDBg2s+hpOkQ0D+BTYfSzJ6lJERMqdl7udPa/2teS5FcHHx6fI+6lTp/L+++8zY8YM2rRpg4+PD0888QTZ2dlXvM9vtwkwDIP8/PwSX3Nxhld+fr7zH+q/nfV1Lf+Av9I9Lx5r2rQpBw4c4Ouvv2bdunU8+uijRERE8M033xAYGMiuXbtYv349a9eu5cUXX+Qvf/kL//d//4efn1+Z66pIloabbdu20bt3b+f7qKgo4L9T9RISEook5pEjR5KSksKsWbOYMGECgYGB9OnThzfeeKPSa7+ciy03u48nkZ9vYrNpZU8RqT4Mw6iQ7qGqYtOmTdx///088MADQEFLzoEDByp1by3DMGjZsiVbtmzhD3/4g/P4tm3byjzjyjAMWrduzebNmxk0aJDz+A8//EBERITzvbe3NwMHDnR2s7Vv3579+/fTpk0b3N3d6du3L3379mXy5MkEBQWxadMm+vfvX/YvW4Es/Vvaq1evK6bRy61F8PTTT/P0009XYFVl1zLYD4ebjZTMXI6eSye8js/VLxIRkSqhefPmrFmzxtki8cYbb3D+/PlKr+Ppp5/mmWeeoX379tx4443861//IiYmxjnA90r27dt3SZdR27ZtmThxIiNHjiQyMpKePXuybNkyvvzySzZv3gzARx99hJubGzfeeCNeXl4sWLAAX19fQkNDWbZsGQkJCdxyyy0EBASwYsUKbDYbLVq0qJDvXx6qbwS3gLvdRpsG/uyIu8CuYxcUbkREXMirr75KfHw8t956K35+fjz55JOlWmi2vDz88MMcOXKEsWPHkpOTw9ChQxk6dGiJVjm+5557LjmWkJDAkCFDSExM5K9//StPPvkkzZo1Y8GCBdx8880ABAQE8Le//Y19+/ZhmiaRkZF8+eWX+Pn5UatWLWbMmMGf/vQnMjMzadWqFYsXL67S4cYwq8JI3EqUnJxMQEAASUlJ+Pv7l9+Ns9Ph2BaWbPiZZ/e34pFbwpl819VTtohIVZSZmUlsbCzh4eF4enpaXU6N1717d1q3bs0///lPq0upUFf6e1ea399quSkvySdg/u8ZaPNkIh+xS4OKRUSkDJKSkvh//+//cdtttwEwf/58Nm/ezNSpUy2uzHUo3JSXoHCwO3DLyyTUOM0vJ9zJyzexa1CxiIiUgmEYrFixgldeeYXs7Gxat27NypUr6d69u9WluQyFm/Jis0OdlnBqN23dTrAqO5jDp1NpEVw1p8mJiEjV5O/vz/r1660uw6W51CJ+VV69gil13QJOA6hrSkRExAIKN+WpXsE285EeJ4CC9W5ERESkcinclKe6BS03YblHAdh1TNswiIiIVDaFm/JU2C3ll3YEO3n8eiKZ3LwrL8EtIiIi5UvhpjwFNgZ3b2x5WbRxnCUrN58DialWVyUiIlKjKNyUJ5utYMYU0DuoYHdXbaIpIiJSuRRuylu9glWJO3mfAmCnxt2IiFQ7R44cwTAMoqOjK/xZ8+bNIzAwsMKfU50o3JS3whlTzSjYzfyXE8lWViMiUuOMHDkSwzAued1xxx1Wl3ZVTZo0YcaMGUWODR48mJiYmAp/dq9evRg3blyFP6cyaBG/8lY4Y6pOeiwAhxJTMU0Tw9BKxSIileWOO+5g7ty5RY45HA6Lqrk2Xl5eeHl5WV2GS1HLTXkrnDHlkXQIT1seqVm5nEzOvMpFIiJSnhwOB/Xr1y/yqlWrFgAPPPAAQ4YMKXJ+Tk4OderUcQaiNWvWcMsttxAYGEjt2rW56667OHToULHPu1zX0YoVK4r8w/bQoUP8/ve/Jzg4GF9fX2688UbWrVvn/LxXr14cPXqU8ePHO1ubirv37NmzadasGR4eHrRq1YpPPvmkyOeGYfDRRx9xzz334O3tTYsWLVi5cmVJf3yXtXv3bvr06YOXlxe1a9fmscceIzX1v5NmvvvuOzp37oyPjw+BgYF069aNo0cLlkbZuXMnvXv3xs/PD39/fzp27Mi2bduuqZ4rUbgpbwGNwMMPIz+XroEF420OnNKMKRGpBkwTstMq/2Wa5fo1hg0bxsqVK4v8Yv7qq69IS0vjvvvuAyAtLY2oqCi2bt3KN998g81m45577iE/v+zLe6SmptK/f3/WrVvHjh076Nu3LwMGDCAurmAYw7Jly2jUqBGvvvoqCQkJJCQkXPY+y5cv55lnnmHChAn88ssvjBkzhlGjRvHtt98WOe/Pf/4zgwYNYteuXfTv359hw4Zx7ty5MtWenp7OHXfcQa1atdi6dSuLFy9m3bp1PPXUUwDk5uYycOBAevbsya5du/jxxx957LHHnAFt2LBhNGrUiK1bt7J9+3ZeeOEF3N3dy1RLSahbqrwZBtRtBce3cbPfadafq82BxFR6tKxrdWUiItcmJx2mNqj85754Ajx8SnXJF198ga+vb5Fjzz//PH/605/o27cvPj4+LF++nIceegiATz/9lAEDBuDv7w/gDDkXffzxx9SrV489e/bQtm3bMn2Ndu3a0a5dO+f71157jeXLl7Ny5UqeeuopgoKCsNvt+Pn5Ub9+/WLvM336dEaOHMmTTz4JQFRUFD/99BPTp0+nd+/ezvNGjhzJAw88AMDUqVN577332LJlS5nGHi1YsICMjAzmz5+Pj0/Bn8WsWbMYMGAAb7zxBu7u7iQlJXHXXXfRrFkzACIiIpzXx8XFMXHiRFq3LhiX2qJFi1LXUBpquakIhV1T17kXbMNwUGvdiIhUqt69exMdHV3k9cc//hEAd3d3/vCHP7BgwQKgoJXmP//5D8OGDXNef+jQIYYOHUrTpk3x9/cnPDwcwNnKUhZpaWk899xztGnThsDAQHx9fdm3b1+p77l37166detW5Fi3bt3Yu3dvkWORkZHO//bx8cHPz4/ExMQy1b53717atWvnDDYXn5mfn8/+/fsJCgpi5MiRztaod999t0jLU1RUFI888gi/+93veP3116/YxVce1HJTEQrDTZO8gr7Gg4kpVlYjIlI+3L0LWlGseG4p+fj40Lx582I/HzZsGD179iQxMZG1a9fi6elJv379nJ8PGDCA0NBQ/vnPf9KgQQPy8/Np27Yt2dnZl72fzWbD/E33WU5OTpH3EydO5KuvvmL69Ok0b94cLy8v7r///mLveSW/naRyuYkrv+32MQyjzN1qV5oYc/H43LlzGTt2LGvWrGHRokVMnjyZtWvX0qVLF1555RWGDh3Kl19+yerVq3n55Zf57LPPuOeee8pUz9Wo5aYi1C1odqudfhiAA4UzpkREXJphFHQPVfarAmabdu3aldDQUBYtWsSCBQv4wx/+gIeHBwBnz55l7969TJ48mVtvvZWIiAjOnz9/xfvVrVuXlJQU0tLSnMd+uwbOpk2bGDlyJPfccw/XX3899evX58iRI0XO8fDwIC8v74rPioiIYPPmzUWO/fDDD0W6gcpbmzZtiI6OLvL9vv/+e2w2Gy1btnQe69ChA5MmTeKHH36gbdu2fPrpp87PWrZsyfjx4/n666+59957L5nNVp7UclMRChfy80g+gsPI5kI6nE3Lpo6va05DFBFxNVlZWZw8ebLIMTc3N+rUqQMUtDYMHTqUDz/8kJiYmCKDcWvVqkXt2rX5xz/+QUhICHFxcbzwwgtXfN5NN92Et7c3L774Ik8//TRbtmxh3rx5Rc5p3rw5y5YtY8CAARiGwZ/+9KdLWlKaNGnCxo0bGTJkCA6Hw1nv/5o4cSKDBg3ihhtu4NZbb+Xzzz9n2bJlRWZeldXp06cvCWX169dn2LBhvPzyy4wYMYJXXnmF06dP8/TTT/PQQw8RHBxMbGws//jHP7j77rtp0KAB+/fvJyYmhuHDh5ORkcHEiRO5//77CQ8P59ixY2zduvWScU3lyqxhkpKSTMBMSkqquIfk55vmtFDTfNnfHDntY7Px81+YPx46U3HPExEpZxkZGeaePXvMjIwMq0sptREjRpjAJa9WrVoVOe/XX381AbNx48Zmfn5+kc/Wrl1rRkREmA6Hw4yMjDS/++47EzCXL19umqZpxsbGmoC5Y8cO5zXLly83mzdvbnp6epp33XWX+Y9//MP831+zsbGxZu/evU0vLy8zNDTUnDVrltmzZ0/zmWeecZ7z448/mpGRkabD4XBeO3fuXDMgIKBIfR988IHZtGlT093d3WzZsqU5f/78Ip//b60XBQQEmHPnzi3259azZ8/L/txefvll0zRNc9euXWbv3r1NT09PMygoyHz00UfNlJQU0zRN8+TJk+bAgQPNkJAQ08PDw2zcuLE5ZcoUMy8vz8zKyjKHDBlihoaGmh4eHmaDBg3Mp5566rJ/t6709640v7+Nwh9CjZGcnExAQABJSUnOUfEV4uO+EP8Tf68ziWnHrucvA9vyUJfGFfc8EZFylJmZSWxsLOHh4Xh6elpdjtQQV/p7V5rf3xpzU1EKBxW3vThj6pQGFYuIiFQGhZuKcnHGVH7BFL+DpzUdXEREpDIo3FSUwkHFddIKNjvTKsUiIiKVQ+GmotS/HgBH6nECSCUxJYukjJyrXCQiIiLXSuGmongFQmDBAOJbfAtWadRKxSLiamrYnBOxWHn9fVO4qUghBXuIdPM5DsAhhRsRcREXV7dNT0+3uBKpSS6u1my326/pPlrEryKFRMLelbS1HQHggLZhEBEXYbfbCQwMdO5F5O3tXezy+yLlIT8/n9OnT+Pt7Y2b27XFE0vDzcaNG/nb3/7G9u3bSUhIYPny5QwcOPCK12RlZfHqq6/yr3/9i5MnT9KoUSNeeuklHn744UqquhTqF7TcNM4+CBRswyAi4iou7kxd1s0WRUrLZrMRFhZ2zUHa0nCTlpZGu3btGDVqVImXYR40aBCnTp3i448/pnnz5iQmJpKbm1vBlZZRYbeUf/oRvMjUmBsRcSmGYRASEkK9evUu2QRSpCJ4eHhgs137iBlLw02/fv2K7MJ6NWvWrGHDhg0cPnyYoKAgoGAfjirLLxh8gzFSTxFhxPHzeU/Ss3Px9lBvoIi4Drvdfs1jIEQqk0sNKF65ciWdOnXizTffpGHDhrRs2ZJnn32WjIwMq0srXv1IADp7HgPg8Om0K50tIiIi18ilmhAOHz7M5s2b8fT0ZPny5Zw5c4Ynn3ySc+fOMWfOnMtek5WVRVZWlvN9cnJyZZVbIKQdHFzLjZ7H+DCjYFBx24YBlVuDiIhIDeJSLTf5+fkYhsGCBQvo3Lkz/fv35+2332bevHnFtt5MmzaNgIAA5ys0NLRyiw4paLlpzWEAYrRSsYiISIVyqXATEhJCw4YNCQj4b8tHREQEpmly7Nixy14zadIkkpKSnK/4+PjKKrdAYbdU/cxY3Mhl97Gkyn2+iIhIDeNS4aZbt26cOHGC1NT/tn7ExMRgs9lo1KjRZa9xOBz4+/sXeVWqWk3AEYDdzKGFcZzo+Avk5WvFTxERkYpiabhJTU0lOjqa6OhoAGJjY4mOjiYurmAn7UmTJjF8+HDn+UOHDqV27dqMGjWKPXv2sHHjRiZOnMjDDz+Ml5eXJd/hqgzD2TV1g/tRUrNyNSVcRESkAlkabrZt20aHDh3o0KEDAFFRUXTo0IEpU6YAkKCU/P8AACAASURBVJCQ4Aw6AL6+vqxdu5YLFy7QqVMnhg0bxoABA5g5c6Yl9ZdYYddUd7+CPaZ2xJ23shoREZFqzdLZUr169briJlnz5s275Fjr1q1Zu3ZtBVZVAQoX87uucBuGn+POM6RzmIUFiYiIVF8uNebGZRV2S4VkHMQgnx1xFywuSEREpPpSuKkMtVuAmyduuWk0MU5xIDGVpAwtZS4iIlIRFG4qg90NgtsC0LNw3M3OeLXeiIiIVASFm8pS2DXV3fc4gLqmREREKojCTWWpfz0ArYyC2V874jVjSkREpCIo3FSWwm6p4IyDQEHLTb4W8xMRESl3CjeVpV4bANzTT1HfrWBAcexZ7RAuIiJS3hRuKovDF2qFA9Cv7llA425EREQqgsJNZapf0DXV1e8kULCYn4iIiJQvhZvKVDjuJuLioGK13IiIiJQ7hZvKFHxdwf8UDirefzKZtKxcKysSERGpdhRuKlNhy4372f2E+ruTb8LOY2q9ERERKU8KN5UpsDF4+EJeNrcGJwOw/2SKxUWJiIhULwo3lclmc3ZNdfAoWKn4yBlNBxcRESlPCjeVrTDctDCPABB7Nt3CYkRERKofhZvKVjjuJiTrEKCWGxERkfKmcFPZCsON/4X9ABw7n052br6VFYmIiFQrCjeVLbhgGwZ72kkaeKSRb0L8eXVNiYiIlBeFm8rm8INaTQDo7n8aUNeUiIhIeVK4sUJh11Qnz2MAxCrciIiIlBuFGysUhptWhdswHNHu4CIiIuVG4cYKhdPBG2UfBuDIGY25ERERKS8KN1Yo3B08MOUgdvLULSUiIlKOFG6sENgEPHyx5WcTbiRwIimDzJw8q6sSERGpFhRurGCzQb2CKeEdPI5hmhB/Tl1TIiIi5UHhxiqF693c6H0S0IwpERGR8qJwY5XCGVMRtnhAM6ZERETKi8KNVQq7pcJyjwAQqxlTIiIi5ULhxiqF3VIBWQn4ka5VikVERMqJwo1VvGqBf0MAWhrx6pYSEREpJwo3VirsmoqwxZGQlElGtqaDi4iIXCtLw83GjRsZMGAADRo0wDAMVqxYUeJrv//+e9zc3Gjfvn0FVljBClcqvt79OKBBxSIiIuXB0nCTlpZGu3btmDVrVqmuS0pKYvjw4dx6660VVFklKQw3bd0Kw43G3YiIiFwzNysf3q9fP/r161fq68aMGcPQoUOx2+2lau2pcgrDTdP8I4BJrFpuRERErpnLjbmZO3cuhw4d4uWXX7a6lGtXuwXY3PDKT6MBZ9VyIyIiUg4sbbkprQMHDvDCCy+wadMm3NxKVnpWVhZZWVnO98nJyRVVXum5eUCdlpC4h9a2OI6caWl1RSIiIi7PZVpu8vLyGDp0KH/+859p2bLkIWDatGkEBAQ4X6GhoRVYZRkUdk21NuLVLSUiIlIOXCbcpKSksG3bNp566inc3Nxwc3Pj1VdfZefOnbi5ubF+/frLXjdp0iSSkpKcr/j4+Equ/CoKp4O3ssVzOiWL1KxciwsSERFxbS7TLeXv78/u3buLHPvggw9Yv349S5YsITw8/LLXORwOHA5HZZRYNoV7TLW1x0MO7D+ZQsfGtSwuSkRExHVZGm5SU1M5ePCg831sbCzR0dEEBQURFhbGpEmTOH78OPPnz8dms9G2bdsi19erVw9PT89LjruUwm0YGnMCD3KIjr+gcCMiInINLO2W2rZtGx06dKBDhw4AREVF0aFDB6ZMmQJAQkICcXFxVpZY8fwbgiMAN/JoZpxgR9x5qysSERFxaYZpmqbVRVSm5ORkAgICSEpKwt/f3+pyCszpB3E/MC77Sbb638b3L/SxuiIREZEqpTS/v11mQHG1Vtg11doWz/ELGSSmZFpckIiIiOtSuKkKCmdMdfQs2IYhOu6CldWIiIi4NIWbqqBwxlRLCqap74hXuBERESkrhZuqoF4EAAG5pwkgVS03IiIi10Dhpirw9IfAMAAibHHsOnaBvPwaNc5bRESk3CjcVBWFXVPt3I+Rlp3HgcQUiwsSERFxTQo3VUVhuOnicxKAHeqaEhERKROFm6rCuYHmUQAt5iciIlJGCjdVRf3rAaiXeRgb+URrxpSIiEiZKNxUFbWagLs39rwswo0EDiSmkpyZY3VVIiIiLkfhpqqw2Z2L+XXzO4Vpwq74JIuLEhERcT0KN1VJ4bibbr4Fg4qj4zXuRkREpLQUbqqSwhlTEbaCndA1Y0pERKT0FG6qkvoF4aZ+xiEAdh5TuBERESkthZuqpHDMjUfacQKMVM6kZnM2NcviokRERFyLwk1V4hUIAQXbMNzilwjAwcRUKysSERFxOQo3VU3hoOKbfRIAOKBwIyIiUioKN1VNYbi5zi0eUMuNiIhIaSncVDWFg4rDcmIBhRsREZHSUripagqng9dKOYCNfIUbERGRUlK4qWqCmoKbF7a8TBobpziZnKltGEREREpB4aaqsdmhXgQAXXxOAOqaEhERKQ2Fm6qocNzNTV4FM6YUbkREREpO4aYq+s02DAo3IiIiJadwUxUVTgdvmFWwDYPCjYiISMkp3FRFheHGNzMBP9I5kJhicUEiIiKuQ+GmKvKqBf6NAGhlxHHsfAYZ2XkWFyUiIuIaFG6qqsLWm06exzFNOHRaXVMiIiIloXBTVRWGm46emg4uIiJSGgo3VVXhdPBWRsGMKY27ERERKRmFm6qqcDp4SNZhDG3DICIiUmKWhpuNGzcyYMAAGjRogGEYrFix4ornL1u2jNtuu426devi7+/PzTffzFdffVVJ1VayoGZgd+Cel0GocZoDCjciIiIlYmm4SUtLo127dsyaNatE52/cuJHbbruNVatWsX37dnr37s2AAQPYsWNHBVdqAbsb1GsNQIRxlKNn08nOzbe4KBERkarPzcqH9+vXj379+pX4/BkzZhR5P3XqVP7zn//w+eef06FDh/Iuz3rB10PCTtq5H+OrrM4cOZtGy2A/q6sSERGp0iwNN9cqPz+flJQUgoKCij0nKyuLrKws5/vk5OTKKK18FM6Y6uA4AVlw4FSqwo2IiMhVuPSA4rfeeou0tDQGDRpU7DnTpk0jICDA+QoNDa3ECq9RYbhpwVFA08FFRERKwmXDzcKFC3nllVdYtGgR9erVK/a8SZMmkZSU5HzFx8dXYpXXqHDGVJ3s4/iQQYymg4uIiFyVS3ZLLVq0iNGjR7N48WJ+97vfXfFch8OBw+GopMrKmU9t8AuBlARaGfEcOFXX6opERESqPJdruVm4cCEjR47k008/5c4777S6nIpX2DXV2hbPodNpZOVqjykREZErsTTcpKamEh0dTXR0NACxsbFER0cTF1ewKu+kSZMYPny48/yFCxcyfPhw3nrrLbp06cLJkyc5efIkSUlJltRfKQrDTaR7PHn5JocS0ywuSEREpGqzNNxs27aNDh06OKdxR0VF0aFDB6ZMmQJAQkKCM+gA/P3vfyc3N5c//vGPhISEOF/PPPOMJfVXisJxN+3cjwOw76QLzfYSERGxgKVjbnr16oVpmsV+Pm/evCLvv/vuu4otqCoqbLkJzzsCmOw/qUHFIiIiV+JyY25qnDotweaOZ34ajYwz7FW4ERERuSKFm6rO7g51C7ZhaG3EsV/dUiIiIlekcOMKLs6YMuI4lZzF+bRsiwsSERGpuhRuXEFhuOnoeQyAfeqaEhERKZbCjSuofz0A1xkF2zBoxpSIiEjxFG5cQUg7AOrlnsCfNM2YEhERuQKFG1fgHQSBYQC0sR3VjCkREZErULhxFYWtN9cZscScTCE/v/j1gURERGoyhRtXURhu2tuPkJGTR9y5dIsLEhERqZoUblxFSHsA2rtfHFSsrikREZHLUbhxFYUtNw3zjuNNpmZMiYiIFEPhxlX41gO/EGyYRBhHNWNKRESkGAo3rqSwa+p6W6y6pURERIqhcONKCrum2tqOcORsGhnZeRYXJCIiUvUo3LiSwnDTzn4E04SYU2q9ERER+S2FG1dSGG6acgwH2Rp3IyIichkKN67EvwF418FOPq2NOHYfT7K6IhERkSpH4caVGAY0+O+g4m1Hz1tckIiISNWjcONqnNswHGH/yWRSMnMsLkhERKRqUbhxNYXh5gb3o+SbsCPugsUFiYiIVC0KN66mMNw0M+NwJ1ddUyIiIr+hcONqAhuDZwBu5NLSiGf70XNWVyQiIlKlKNy4GsMospjfjrgL5OblW1yUiIhI1aFw44oadACgs9sh0rPztBWDiIjI/1C4cUWhXQC42f0AANs17kZERMSpTOFmzZo1bN682fn+/fffp3379gwdOpTz5/WLtsKFFYSbBrnxBJGsQcUiIiL/o0zhZuLEiSQnJwOwe/duJkyYQP/+/Tl8+DBRUVHlWqBchncQ1G0NQCfbfrYf0aBiERGRi8oUbmJjY2nTpg0AS5cu5a677mLq1Kl88MEHrF69ulwLlGIUtt50tsdwIimTExcyLC5IRESkaihTuPHw8CA9PR2AdevWcfvttwMQFBTkbNGRChbWFYDujoJxN+qaEhERKeBWlotuueUWoqKi6NatG1u2bGHRokUAxMTE0KhRo3ItUIpR2HLTPPcQXmSy/cg57m7XwOKiRERErFemlptZs2bh5ubGkiVLmD17Ng0bNgRg9erV3HHHHeVaoBQjMAz8GmAnj/a2Q2q5ERERKVSmcBMWFsYXX3zBzp07GT16tPP4O++8w8yZM0t8n40bNzJgwAAaNGiAYRisWLHiqtds2LCBjh074unpSdOmTfnwww/L8hVcn2FA45sBuNHYz96EZFKzci0uSkRExHplCjc///wzu3fvdr7/z3/+w8CBA3nxxRfJzs4u8X3S0tJo164ds2bNKtH5sbGx9O/fn+7du7Njxw5efPFFxo4dy9KlS0v9HaqFsIJwc4vjAPkmRGsTTRERkbKFmzFjxhATEwPA4cOHGTJkCN7e3ixevJjnnnuuxPfp168fr732Gvfee2+Jzv/www8JCwtjxowZRERE8Mgjj/Dwww8zffr0snwN11cYbiKJwU4eWzUlXEREpGzhJiYmhvbt2wOwePFievTowaeffsq8efMqtBXlxx9/dM7Muqhv375s27aNnJycy16TlZVFcnJykVe1US8CHAF45mcQYRxlmzbRFBERKVu4MU2T/PyCzRrXrVtH//79AQgNDeXMmTPlV91vnDx5kuDg4CLHgoODyc3NLfa506ZNIyAgwPkKDQ2tsPoqnc0OoZ0BuNG2nx1xF8jRJpoiIlLDlSncdOrUiddee41PPvmEDRs2cOeddwIFY2J+Gz7Km2EYRd6bpnnZ4xdNmjSJpKQk5ys+Pr5C66t0hYOKb3Y/QHp2HntOVKOWKRERkTIo0zo3M2bMYNiwYaxYsYKXXnqJ5s2bA7BkyRK6du1argX+r/r163Py5MkixxITE3Fzc6N27dqXvcbhcOBwOCqsJssVjru5ybYfMNl65BztQgOtrUlERMRCZQo3kZGRRWZLXfS3v/0Nu91+zUUV5+abb+bzzz8vcuzrr7+mU6dOuLu7V9hzq7QGN4Ddg4C88zQ2TrHtSAiPdLe6KBEREeuUKdxctH37dvbu3YthGERERHDDDTeU6vrU1FQOHjzofB8bG0t0dDRBQUGEhYUxadIkjh8/zvz58wF4/PHHmTVrFlFRUTz66KP8+OOPfPzxxyxcuPBavoZrc/csCDjxP9HFtpd1R8IwTbPYbjoREZHqrkzhJjExkcGDB7NhwwYCAwMxTZOkpCR69+7NZ599Rt26dUt0n23bttG7d2/n+4s7io8YMYJ58+aRkJBAXFyc8/Pw8HBWrVrF+PHjef/992nQoAEzZ87kvvvuK8vXqD7Ce0D8T3S3/8qitN7EnkmjaV1fq6sSERGxhGFeHJFbCoMHD+bQoUN88sknREREALBnzx5GjBhB8+bNq3RLSnJyMgEBASQlJeHv7291OeXjyGaYdycXbIG0T3+fN+9rx6Abq9GsMBERqfFK8/u7TLOl1qxZw+zZs53BBqBNmza8//77rF69uiy3lGvR6EZw9yYw/wKtjHgt5iciIjVamcJNfn7+ZQfwuru7O9e/kUrk5nDOmupm+1XhRkREarQyhZs+ffrwzDPPcOLECeex48ePM378ePr06VNuxUkpNO0JQDfbLxw5m05iSqbFBYmIiFijTOFm1qxZpKSk0KRJE5o1a0bz5s0JDw8nNTW1xJtgSjkLLwg3Xez7sJPH9iPnLS5IRETEGmWaLRUaGsrPP//M2rVr2bdvH6Zp0qZNG1q2bMmUKVOYM2dOedcpV1M/Erxq4ZNxnnbGIbYcaUa/60OsrkpERKTSlWm2VHF27tzJDTfcQF5eXnndstxVy9lSFy16CPauZHrOH9hQfySfP32L1RWJiIiUiwqfLSVVlHPcza/8eiKJlMzL75QuIiJSnSncVCdNCxZE7GiPwcPM4vuDFbdDu4iISFWlcFOdBDUF/0Z4kMuNtv2s35dodUUiIiKVrlQDiu+9994rfn7hwoVrKkaukWEUdE1FL6Cb7Vc+2ncj+fkmNpv2mRIRkZqjVOEmICDgqp8PHz78mgqSaxReEG5usf/K66lZ/HIiichGgVZXJSIiUmlKFW7mzp1bUXVIeQnvAUAbIxZ/Ulm/L1HhRkREahSNualu/EOgTktsmNxk28e3GncjIiI1jMJNddSkYH2bLra97DyWxOmULIsLEhERqTwKN9VRk+4A9HLsB+C7/Wq9ERGRmkPhpjoqbLlpmhdLQOG4GxERkZpC4aY68q0HdVphYNLZto9NB86QnZtvdVUiIiKVQuGmuipsvent2E9qVi7bjpyzuCAREZHKoXBTXYUXjLvp6VEw7kZdUyIiUlMo3FRXjQtabhpkHSoYd6NBxSIiUkMo3FRXvnWhbmsMTG627+Pw6TSOnk2zuioREZEKp3BTnRWOu7k74BAA3+0/bWU1IiIilULhpjorDDedjT0AfKuuKRERqQFKtbeUuJjCcTd10g4QSAo/HrKRmZOHp7vd4sJEREQqjlpuqjPfulA3AoA7fA+RlZvPj4fPWlyUiIhIxVK4qe4ujrsJPAzAd5oSLiIi1ZzCTXVXGG6uz9kNwLf7T2OappUViYiIVCiFm+qucVcAfJNiqG3PIO5cOofPaEq4iIhUXwo31Z1vPagVjoHJoJBTAHyrrikREanGFG5qgrAuANzmGwtovRsREaneFG5qgtDOALTO3QvAlthzpGXlWlmRiIhIhbE83HzwwQeEh4fj6elJx44d2bRp0xXPX7BgAe3atcPb25uQkBBGjRrF2bOa3nxFoQUtN16J0YTXcpCdl88Ph/QzExGR6snScLNo0SLGjRvHSy+9xI4dO+jevTv9+vUjLi7usudv3ryZ4cOHM3r0aH799VcWL17M1q1beeSRRyq5chdTtzU4/DGyUxkUlgxotWIREam+LA03b7/9NqNHj+aRRx4hIiKCGTNmEBoayuzZsy97/k8//USTJk0YO3Ys4eHh3HLLLYwZM4Zt27ZVcuUuxmaDRjcC0NO7YNzNz0fPW1mRiIhIhbEs3GRnZ7N9+3Zuv/32Isdvv/12fvjhh8te07VrV44dO8aqVaswTZNTp06xZMkS7rzzzmKfk5WVRXJycpFXjVQ4qDg84xcAYk6lkJ6tcTciIlL9WBZuzpw5Q15eHsHBwUWOBwcHc/Lkycte07VrVxYsWMDgwYPx8PCgfv36BAYG8t577xX7nGnTphEQEOB8hYaGluv3cBmFg4q9ErZRz89Bvgm/nqihQU9ERKo1ywcUG4ZR5L1pmpccu2jPnj2MHTuWKVOmsH37dtasWUNsbCyPP/54sfefNGkSSUlJzld8fHy51u8yGnYCwwZJcfQMyQFgZ/wFi4sSEREpf5btCl6nTh3sdvslrTSJiYmXtOZcNG3aNLp168bEiRMBiIyMxMfHh+7du/Paa68REhJyyTUOhwOHw1H+X8DVOHwhuC2c3EUfnyMsJoydx5KsrkpERKTcWdZy4+HhQceOHVm7dm2R42vXrqVr166XvSY9PR2brWjJdrsdQPsllUToTQBEmvsA2HVMLTciIlL9WNotFRUVxUcffcScOXPYu3cv48ePJy4uztnNNGnSJIYPH+48f8CAASxbtozZs2dz+PBhvv/+e8aOHUvnzp1p0KCBVV/DdRQOKg5O2gXA0bPpnE/LtrIiERGRcmdZtxTA4MGDOXv2LK+++ioJCQm0bduWVatW0bhxYwASEhKKrHkzcuRIUlJSmDVrFhMmTCAwMJA+ffrwxhtvWPUVXEvhoGK3U7toXduNfWdz2XU8iZ4t61pcmIiISPkxzBrWn5OcnExAQABJSUn4+/tbXU7lMk14OwJSEpgZ9i5vx9Ql6raWjL21hdWViYiIXFFpfn9bPltKKpFhOMfddHU/CGjcjYiIVD8KNzVNYbhpkbkTgOj4JA3GFhGRakXhpqZp1hsA/1Nb8LFlcyY1i4SkTIuLEhERKT8KNzVN3dYQEIqRm8l9QQX7TKlrSkREqhOFm5rGMKD57wC4w7EbKOiaEhERqS4UbmqiFrcBcH3GVkAtNyIiUr1Yus6NWCS8B9jc8UuPp4mRwO5jbuTnm9hsl9/TS0RExJWo5aYmcvhB45sBuM19FylZuRw+k2ZxUSIiIuVD4aamal7QNdXf81cAorVDuIiIVBMKNzXVxXE3ObvwJIvvD56xuCAREZHyoXBTU9VtDf6NcDOz6WLbw7f7E8nL12J+IiLi+hRuairDcLbe9PXYzYX0HHbEnbe4KBERkWuncFOTFYab37nvAmDd3kQrqxERESkXCjc1WeGU8Lo5J2hiJLB+3ymrKxIREblmCjc12f9MCe9n30bMqVTiz6VbXJSIiMi1Ubip6a4fBMCjHl/jQQ7r96lrSkREXJvCTU0XOQj8QgjKP8vv7d+zbq+6pkRExLUp3NR0bg7o8gQAj9s/Z8vhM6Rm5VpclIiISNkp3Ah0HIXp8KeZLYGe5lY2H9CCfiIi4roUbgQ8/TFufASAJ9w+55s9Jy0uSEREpOwUbqRAlyfIt3nQwXaQpP3fka/VikVExEUp3EgB33qY7YcC8ED2Mr7dr1lTIiLimhRuxMnebSz52Oht38mi5cs0sFhERFySwo38V+1m5F//BwCezXyP6V/usrggERGR0lO4kSLc+r1OtmdtWtqOU/vnd/np8FmrSxIRESkVhRspyjsIjwFvA/CEfSUf/XsFGdl5FhclIiJScgo3cqnrBpLT6m7cjHyi0t9lxle/WF2RiIhIiSncyGW5D3ibbI9A2tiO4vl/M9l/MsXqkkREREpE4UYuz7cuHgPeAuAp+3KWLvvM4oJERERKRuFGitf2PtJa3oO7kcfjp17hp+3bra5IRETkqhRupHiGgc8fZnPCO4IgI5XgL0eRm55kdVUiIiJXZHm4+eCDDwgPD8fT05OOHTuyadOmK56flZXFSy+9ROPGjXE4HDRr1ow5c+ZUUrU1kLsXviP/zWkCCc8/SsK8EZCfb3VVIiIixbI03CxatIhx48bx0ksvsWPHDrp3706/fv2Ii4sr9ppBgwbxzTff8PHHH7N//34WLlxI69atK7Hqmse/XhhbOr9HlulOaOK3ZH39itUliYiIFMswTdOyHRJvuukmbrjhBmbPnu08FhERwcCBA5k2bdol569Zs4YhQ4Zw+PBhgoKCyvTM5ORkAgICSEpKwt/fv8y11zQ5efm89bdXeCHzXQCiI57Dv88zhNfxwTAMi6sTEZHqrjS/vy1rucnOzmb79u3cfvvtRY7ffvvt/PDDD5e9ZuXKlXTq1Ik333yThg0b0rJlS5599lkyMjKKfU5WVhbJyclFXlJ67nYbNw18ir/lDAKg/d43mT3jz9z4129Yv++UxdWJiIj8l2Xh5syZM+Tl5REcHFzkeHBwMCdPnrzsNYcPH2bz5s388ssvLF++nBkzZrBkyRL++Mc/FvucadOmERAQ4HyFhoaW6/eoSXq3rkefR19nS0jB7uGvu/2TTumbiPr3Ts6lZVtcnYiISAHLBxT/tkvDNM1iuzny8/MxDIMFCxbQuXNn+vfvz9tvv828efOKbb2ZNGkSSUlJzld8fHy5f4eapGOT2nR+7APo8BB2w2SmxyzaZv7MtFV7rS5NREQEsDDc1KlTB7vdfkkrTWJi4iWtOReFhITQsGFDAgICnMciIiIwTZNjx45d9hqHw4G/v3+Rl1wjw4AB70Kb3+NBLn93f5v9P29gS+w5qysTERGxLtx4eHjQsWNH1q5dW+T42rVr6dq162Wv6datGydOnCA1NdV5LCYmBpvNRqNGjSq0XvkNmx3u/Sc07YWPkcU8jzf4+9LVZOdqmriIiFjL0m6pqKgoPvroI+bMmcPevXsZP348cXFxPP7440BBl9Lw4cOd5w8dOpTatWszatQo9uzZw8aNG5k4cSIPP/wwXl5eVn2NmsvNAYP/RW79DgQZqbya8ic+W/eT1VWJiEgNZ2m4GTx4MDNmzODVV1+lffv2bNy4kVWrVtG4cWMAEhISiqx54+vry9q1a7lw4QKdOnVi2LBhDBgwgJkzZ1r1FcThh9tDS0jxCaehcZauPz5SbBehiIhIZbB0nRsraJ2bimFeiOPczN7Uzj/DPrcImk5Yh4eXr9VliYhINeES69xI9WIEhpH9wBKS8KF17l5iPxwEeblWlyUiIjWQwo2Um5AWHdjf5yMyTXdaJX3PsU8eg5rVMCgiIlWAwo2Uq849+vN5y7+SZxo0OrKUpC+nWF2SiIjUMAo3Uu4GDnmUv/uPBSBg20xy/+9jiysSEZGaROFGyp273cbA0ZOYbRTsQ2VbMxEOrLO4KhERqSkUbqRCNAj0wqPPJJbk9cBm5mEuHgknf7G6LBERqQEUbqTCDL2pMdM9nuCHvDYY2Snw6SBITrC6LBERqeYUbqTCeHnYGdWjFY/njOOo0QiSsxgp0gAAIABJREFUj8PCwZBz+U1ORUREyoPCjVSoB7s0xu5di2GZz5LlEQQJO+GLKE0RFxGRCqNwIxXKx+HGI92bcsysxyT7eEzDBjs/hW1zrC5NRESqKYUbqXDDb25MgJc7y843Y2+bqIKDq5+HY9usLUxERKolhRupcH6e7jzcLRyAu37uwFqzM+TncOqjQSxYv93i6kREpLpRuJFKMbJbE0ICPMk3DcZnPcah/BCCOUvTDU9zLkUDjEVEpPxoV3CpNNm5+ZxNyyI7Nx8S91FvUX+8yOT/wh7lpoenW12eiIhUYdoVXKokDzcbIQFeNK7tQ+OIjuzp+AoAN8Z9RPZ+rWAsIiLlQ+FGLNOu/xj+Y78NGyb5Sx/RAn8iIlIuFG7EMm52Gxd6/IU9+Y3xzD6PuWQU5OVaXZaIiLg4hRux1P1dWvCCLYoU0wsj7kf4/+3deXwU9f3H8dceye7m2lwkIXdCuOROwhVAVBBLUYulCipXPbEioG0VautVLbZaa/0pFBRBBYFSULFVK4ggh3IHuQkQIOYgJJD72Ov7+2Ng45oQQwlsCJ/n4zGPmNmZ2e9+EjJvv/P9znz1krebJIQQ4gon4UZ4lb/JyKD+/XjSfq+2Yv3LkP+tdxslhBDiiibhRnjdhIxEPtMN4FNnb3A5sC1/COWwebtZQgghrlASboTXRQSaGZUWyx/s93BGBeBbtIc5M6fyuw92U1krY3CEEEJcGAk3okV46uYu3DUknXetDwHwS8c/2bplE/+35rCXWyaEEOJKI+FGtAgWXwOP3diBqY8+ibP9TzDpHLzk8w8WfX2E05VyiUoIIUTTSbgRLYtOh+GWV1FmKz31R7nL+THzNhz1dquEEEJcQSTciJYnqC26m2YC8JjxX3y1aRMlVdJ7I4QQomkk3IiWqeddqJQbMensPKNm8fZ6GXsjhBCiaSTciJZJp0N3y6s4jP6k6bNwbppNaZXd260SQghxBZBwI1ouayz6n/wJgEdYzIrV67zcICGEEFcCCTeiRdOnTeBURAZmnZ3uO56kvKrG200SQgjRwkm4ES2bTkfYmNlUYSaNA2T/6/febpEQQogWzuvhZtasWSQlJWE2m0lLS2P9+vVN2m/jxo0YjUZ69ux5iVsovE0fmsi2bs8A0P3om6j9//Z4vbiilif+9S2bjhR5oXVCCCFaGq+Gm6VLlzJt2jSefPJJdu7cyaBBgxg+fDgnTpxodL/S0lLGjx/PkCFDLlNLhbf1HHEf76nhADhXPAhFdbOnZn56gKXbcnj+3/u91TwhhBAtiFfDzSuvvMK9997LfffdR+fOnXn11VeJi4tj9uzZje734IMPctddd9G/f//L1FLhbUFmHw71eIKtrg4Y7RWwdCzYKtmbV8ryHd8BsC+/jKKKWi+3VAghhLd5LdzYbDa2b9/OsGHDPNYPGzaMTZs2nXe/+fPnc+TIEZ5++ulL3UTRwtyd0Y5f2aZSqILh1H7Uh7/ixf/sQ6m6bTYelktTQghxtfNauCkqKsLpdBIZGemxPjIykoKCggb3ycrKYvr06SxatAij0dik96mtraWsrMxjEVemTlFBJCW241e2KTh1BnT7PmTY8ZfxNegY3jUKgA1ZEm6EEOJq5/UBxTqdzuN7pVS9dQBOp5O77rqLZ599lg4dOjT5+DNnzsRqtbqXuLi4i26z8J6x/RPYpjrxtP4RXOgYZ1zNgvhPGdMnHoANh4tQ3+/KEUIIcdXxWrgJDw/HYDDU66UpLCys15sDUF5ezrZt25g8eTJGoxGj0chzzz3Hrl27MBqNrFmzpsH3mTFjBqWlpe4lJyfnknwecXn8pEsU4QEmFlb24Un7PQBk5L9LRt67+Br05JfWcORUpZdbKYQQwpu8Fm58fX1JS0tj1apVHutXrVpFRkZGve2DgoLYvXs3mZmZ7mXSpEl07NiRzMxM+vbt2+D7mEwmgoKCPBZx5fI16rmzj9b7ttg5hC0p0wDwWfscT4ZrdzDekHXKa+0TQgjhfU0buHKJPPbYY4wbN4709HT69+/P3LlzOXHiBJMmTQK0Xpfc3Fzeffdd9Ho9Xbt29dg/IiICs9lcb71o3e7qG887m47R1mqh55inYZ0R1r/MhNLZnDQUsyGrDRMHJHm7mUIIIbzEq+Fm9OjRFBcX89xzz5Gfn0/Xrl355JNPSEhIACA/P/9H73kjrj5trRbWP34DvkY9vkY93PB70Btg3Z953OefzMuuwe5YgI/R4O2mCiGE8AKduspGX5aVlWG1WiktLZVLVK2Ma+P/oV+lPZ6hsMOdRIx5Qws9QgghrngXcv72+mwpIZqLfsAjLIr8DS6lI+LQYlj4cyhv+LYCQgghWi8JN6JVMaZPYLL9EWowwdG1MHsAZK32drOEEEJcRhJuRKsysH0bPnH141bbC9SEdYaqIlg0ikXPjeVQzklvN08IIcRlIOFGtCoxwRaSw/055IqmR+4TLHBoj/e42/UxYfP749q5CFwuL7dSCCHEpSThRrQ6Q6/RbgJp0/nyWfxjrO75d75TbQhzFaP/6FcwdzBkf+XlVgohhLhUZLaUaHWqbU7WHTpFjzgrba0WABZtOMjxT//GI8YPCdRVaxsmX8fJ9Mf507d+dI22ct+gpAYf/SGEEML7LuT8LeFGXBVcLsUv/rGJYydO8HLEZ9xQ8R9w2QFY5UzjZcft3Dx0KI8Mae/llgohhGiITAUX4gf0eh0zf96dMr2Vewrv4NHIeSxzXItT6bjRsJ1PfWcQvXYa/1q9wdtNFUIIcZEk3IirRseoQB4cnAzAB9lGHndOYkGvJbg6j0SvU4wybODW9bdy+J2HoUTujC2EEFcquSwlrio1diej535DcUUtfx7VnQEp4QCo3B1kL3mc5PKtdRvH94dut8M1I8E/zEstFkIIATLmplESboTLpdDpqDd4WCnFm++8TZcj8+iv34ded/afhs4AbXtAQgYkDID4fuAX6oWWCyHE1UvCTSMk3IjGOJwuJs7fyuHDBxkbuJ1JIdsxFu722MaFjqrQLgR0uh6SBms9PKYAL7VYCCGuDhJuGiHhRvyYkiobt76+kROnq8hoF8Y7o9pyZv9X7PzqY1Kqv6WdPt9zB50BorppPTvx/SCuHwRGeqfxQgjRSkm4aYSEG9EUBwvKuW3WRqpsTq7t0IZtx05TZXNitfgwsp2B8gNr6MMeBuj3Eqc/Vf8AockQ35+yNqkUBnSmyJJEucOAUa9jcIc26PXNez8dp0vhUgofg8wREEK0ThJuGiHhRjTVZ3sKmLRwu/v7fsmhvHJHT6KDLeSVVDNr7WGWbs0h3FnEhNgC7k88iSHnGzi5F/D8Z2VXBo6oaPaqBIJSBnDj8NsgvCPoLz6MnLuHT35pDR8/MpDwANNFH1MIIVoaCTeNkHAjLsSbXx1lzldHuHdgMg9cm4zhBz0uW4+dZty8zdTYXdzSI5pXR/fEXlnCW4uXoE58Q5ruEF0MJ7BSUf/glhCITtV6eUKTICQRwtpr3xuMTW7j90PYxIxEnrm1y8V8ZCGEaJEk3DRCwo1obl8eLOT+d7bhcCnuSI/l6KlKth0/g49Bx8u39+BnPaKhLBcK9rBmzWeY8raQajiMhdoGj6cMJnQRnSCiC0R00np42nSA4ATQGzy3VYrbZm0iM6cEAB+DjjW/vo64UL9L/rmFEOJyknDTCAk34lL4eFceU5bs5Ny/pkCzkbnj0unfzvP+ODV2J7fN2kRW/mlGx5zmuX5w5NAejh3eR5QznxRdHn66hkMPBpPWuxOSoH21xnK03MgrX+VTY/AjoE08K/OsjOwVxyuje17SzyuEEJebhJtGSLgRl8riLSeYsWI3McEW5v+yNx0iAxvc7uipCm75vw1U2pwkhPlxvLgKgI6RgdgdDhynj9FZd4IbQk/x06gyAsuPQlEWOM8Ter6nQpnJVO3omD6UNtFJni+areDfBvzDwT9Cu1ePPChUCHGFkHDTCAk34lI6XlxJm0ATfr6Nj5n5KDOXqUsyAfA16plyQwoPXNsOheKt9dm8vuYw1XYnUUFmPpk6iFCLQXskxJlj7qW08DhbDhwnQFdDaqQeU+lxsJU3vbG+gRCWrI3xCUnEZmlDiT6UIoIJDosguk0Y+PiDjwV0elBOcDlBucAc3CyDoYUQoqkk3DRCwo1oKeasO8KevDKmDW1PuzaeNwHMK6lm7LzNHD1VyeAObZg/sXe96eOPLc1kxc5cRnRryxt3p4LLSc6hHcxZuJgeZDE02UyIn6+2sXJBTSlUntKW6jMX13i9DwS1haAYbbHG1i0BEWdDkRl8/LQgZPS9uPcTQlz1LuT83fQpGUKIZvXg4HbnfS062MKsu1P52esbWXfoFLPXHeHh61Pcr+eWVLNyV97Z42gPA0VvIK5Tb5ypZn675QSdygJ59/Y+RASaPY59rKiSuWv2smfvbiLsuSTqCojVnSJcV0qUvpQIXQn+qhJ/XS1mbA030GXXepKa9IBRHQRGccY3ih0lAfgEtyWjR2eMgRHgF6YFpXOUE2wVUFuhfQXtElpAG+2rf7g2y8zg0/BbCSEE0nPj7eYI0ah/bs3h8eXfotfB+/f3Iz0hRAs7a4+w7fgZMtqF8f79/Tz2KSit4aZXv6K02k5UkJk549LoEReMUoqF3xznT58coNruBCAm2MJtvWIY3i2K+FA/AkxGymsdjHx9I0eLKumfFMx747tj1OuYt+k4M/97GIBwSnlpWBiDIm1Q+h2U5kJpjvbflafAXg2OGrBXXZrCmKzgFwKBbSEoWus9Cmyr9RDpDNqsMr0P+PqBrz8Oox92gx8WfyuYAsHXX2tjRaHW3qpirccprL0WoJppLJJSipIqOyH+0nMlxMWSy1KNkHAjriRKKX6z7FuW7/iOMH9fjAYdJ8u0gcU+Bh0L7+1L3+T6Tyw/eqqCB97bzuHCCnyNemYM78SaA4WszyoCoH9yGNOGtqd3YmiDd0vOOlnOyDc2Umlzcu/AJExGPbPWHgGga0wQe3LLMPvoWfHQAK6JbvjfkcPp4usjRbz0wUYoySFWX8TwGBuFBTkEq1JS/KrpGurAoFx1O+n04BugPavLNwBQdQGk4uTFX05rCrMVQpLOjjU6G5QMPmA0g9GkfdXptPFHLgc47VqQs1VCbbkWmnz9wGxl3xk9O4p09OjRm269+kFEZwiIbDw8KaWFwtoKcFRrl/XM1rp9XC4oz4PT2dp258KdJaTh4yqltc1Rox3rAu6hJC6SoxaKD4PTBlE9ZJzaRZJw0wgJN+JKU2Vz8LPXN5JVqF2mCfHzYVRqLGP6xJES0fCMLIDyGjuPLt3F6v0n3etMRj3Th3diQv/EH30ExKe783lo0Q6PdU/8pBMPXJvMxPlbWJ9VRFyohZUPDyTE3xelFMeKq9iQdYr1WUV8faSY8loHoPUQ/fWOHvRLDuObo8Xcu2ArlTYn6QkhvP3L3gSZf/wy05oDJzldVkXnEBfJ/rVY7KVQng9ledpSUaCdRFwuUE6U005h8WmKz5zGomoI0NUQqKvB/P37C5mt2M3hfFdjJkJ3Br/qfHRc4j+JBpMW4uBsGPnBz8FRrY2R8tjHV5vp5mOBkpyGZ84ZLVqvlPu4aEHLVvG94+m0nqmAKPAP08ZEGc3acU2B2nsERGhfdXotFNmrtONYQrQgFRilBTQ4O8DcCbaqsz+H77SvTru2vV+o9tVRC1WntR6y6jOgN2pB0ceiBUenXfvZOc9eBjUFgilIWyzB2uVLvzAtnLns2rGqT2vjyPQ+deO73AHUpNXZ4HP5ZgTaKiF3B+Rs1r6eOgBnsutqHxQL3UZBtzsgqmvzvrdScOogHFuv1TY4DqxxWuj19b/4GjhqtTBtq9R+P+3V2vtE99R+vpeJhJtGSLgRV6Kc01W8tf4ovZNCufGaSExGw4/vhPZohtfWZPH3L7LoHhvMX2/vQUpE059g/pfPDjBr7RH0Onjhtm7c2Sce8Hy4aJ/EUBLD/dh4uJjckmqP/a0WH0Z0b8v04Z08AszOE2eY8PYWymocpEQE8Nb4dBLD/c/bjtlrj/Dnzw64v9fpIC7Ejw6RgXSMCqBDZCDt2gRgNOi052y54K0NR/koUxuXdFOXSLYfP0NRhY0706OZeXMyGM0cKrZx91ubOVWuhYXbu4fx7CA//KpytROuy6GdnJw27Q+8o0ZbXE7txKk3aouPRetp8g0AHzO26kpe/mgzNRWnidCVkqLLJc2vgDa23PrB5bx02snaUV3/Jb0RguO1E1dZPlQVNfGYVzodP3y0SaMMJi2IBUZqocwvTAtM5iDt0qZyaUHRUVsXBGvLzy5lWmizV2kndb1BC31+4VpAPDdIv6YUKou0MKOc9dtgCjrbe/a9mYzB8dC2B0R204KOcmmXdsu+03oqfQPqQqYlRPs9dNRqbXU5tTqcCywFu+HwF9q+DdH7nP28Z4Oif5u6cWwG37Ohs0gLnnrj2SAZrvUWnjmmHb/ooNaGhrTpDHF9tEBVdeZsgD2t/W7evqDpP6smkHDTCAk34mpUWm0nyGxEd4H/B+d0KRZvOUG7NgH1bki4P7+Mn8/a5B6/A+Br0NMrPphrO7RhYEo4XWOs9R5Zcc6+vDLuWbCVgrIarBYfZt2dyoCU8HrbfT/Y9Ii1kltSTVHFeQY6/4BBr2PG8E7cOzCJTUeKGTtvM0rBK3f0oENkIOPmbeZMlZ2YYAsFZTU4XYrkcH9evyu13uW248WVrNp3ki/2FxIa4Mvf7uiJr7HhywznQmFEoIkXbuvG/e9uQ6eDjx5Io3vI2bYrRb0TtVJ1QcnHT7uMYa/GUV7InE83s/NwLmNuHMDQvqkel5cKT5fw52VfYnBUMaBdGAPbtyHMz0c7hilQu8xnNGsnnoqTUH5SO6G5x0ZV152kKwu1EyxoJygfP60npLpEuxxWll8/cOkMdZfHgqK17c/1rlSf0d7bL7Su90W56sKi0659FoOvtiilBYtzAaO6RDtWbann+1lCtBOwyw72mroxXuc7CV8OQTHaiT62N0R20e4uHhilfdas/8LuZXDov3U9VM3JaIaEDK2GJTnaGLjasuY7vilI+9n5nO3pqy2H00fPv71fODx+pPneHwk3jZJwI0TzWXPgJG9+lU33WCsZKeH0Tgz50Xv8fF9hWQ0PvLedzJwSDHodv/tpZ27rFUOInw86nc4j2Dx2YwemDGkPQFFFLYcKyjl0spxDhRUcKijnWHEVoNDpdBh0OsIDffnDiGs8xiT9bdUh/v5FFhYfA0aDjvIaBz1irbxzTx+yCiuYsngn+aU1GPU62gabCTT5EGQxUlxhc18WPGfy9Sn85qaO9T7T3rxSbn19I06XYu64NIZ1ieLRpZl8sDOXbjFWPnx4wHkDX0NsDhdTl+zk0z0FgPY/7H/+eXfu6B0HaKFr3LwtnDhdN3hbp4P0hBAeu7FjvVB60c6N4dHpQGfA5tJxutpJVPAlfuSHw3Y2KJm0E+35xq+4vtcbU1umBbnyfC3UVZ3W1tWUal91hrOXsny1r6bAusU3oC7c+fproamy6OztFIq0nhyztW5MVOQ12q0QfkxNGeTthJN7tF6Rk3u1QGKN0S5dBUZqweHcWLOaUq2X0GDS2qk31gVjpbRAlTIUEgdooeOH73Xus9aUQU3J2eMWQsUpLWT5h9dd9nM5tdBbWaTV2hoLUd20JSim/uWtilPw3RY48Y0WZM8dxxKq9RB1/Mn/9KM+Hwk3jZBwI0TLUmN38rsVu1mxM9e9zmrxITrYwv587f88f31jBx45G2wuhtOlGP/2ZjYeLgagT2Io8yamE3j2ktmZShu/WbaLLw4U1tvXoNfRNymUDpGBLNh0DL0Olj+UQa/4ujEHDqeLkbM2sie3rO7+Q0BheQ1DXl5Hea2DP47syrh+CU1qb43dyaSF21l78BS+Bj0DUsL48uApAJ69tQvpiSFMeHsrRRW1xIf6cWefeFbtK2DHCe1ZY36+Blb8KoNOUef/W6eUYtvxM9idLjLa1e85a8zBgnIeWrido0WV3NIjmt8O60h8WNNDzp7cUtYeLGRcv0Ssfs03vb+02s6v/5lJzulq3rg79YIuxYqWS8JNIyTcCNHyKKWYv/EY8zZk1xu301zB5pxT5bVMWridmGALfx7VHYtv/YeRHi+uorjSRlmNnfIaB0a9jgHtwt0n4KlLdvJRZh7J4f78Z8ogLL4Gymrs/Pqfu1i17yRWiw+rHxtMm0CT+7gLNmbzzMf7CDIbeWtCb/okhdZr2/HiSnLPVFNWY6esxsG/tn/HluzTmH30zB2XzqD24Tz/n/3M25ANgNlHT43dRee2QbxzT2/3PY3ySqr5zbJdbDpSTHyoHysnDyDYz3M6elmNnQ925LLwm+PuXqlfpMXy7K1d8DdpvW9Ol2LJ1hPMW59N1xgr9wxMomdcMAAf7sxlxordHpclfQw6xvVL5OHr2xEWYOJ8lFK8981xnv/3fmxOFwNTwnnnnj4X1KN1PgWlNUycv4UDBdoYl/AAXxbe19cj4CmlOFBQTpDFh5hgy/kO1SQ1dief7SkgIyWs3j2lmpPLpXj+P/vZk1vK38b0vOh2N6fMnBJq7c4GZ242Jwk3jZBwI0TLVm1zcqy4kqOnKomymkhLqB8CvK20ys6wV9dxsqyWiRmJjO4dx0MLt3OsuApfg57X7uzFT7pGeezjcLoYNXsTu74rRaeD+wYm8ethHTH7GNiVU8Lfv8hiTQM9RoEmI2//sje9E7U6KKX426pDvLZGu+dQn8RQ3pyQjtXi2fNxptLGrW9sIOd0NQNTwlnwy94YDXpOltXwj3VHWLo1hyqbFkwsPgZqHE6UgqRwf/7vzl7YnC6e/mgvu3NLPY7bKz6YxDB/Pjjb0zaofTgPXdeO2WuPuG81oNNpz0pLTQghLT6Ea6KDSAr3x+xjoKLWwYwVu/n47E0oz3l0aAemDr24EHu4sJwJb28lt6SaiEATof6+HCgoJ9jPh/fu6UvXmCDWZxXxyqpDZOZovVvRVjNpiaGkJ4TQJymUjpGBPzqT8JyC0hoefG8bu74rJSHMj5UPD2zWHqjve/HTA/xjnTaGpUNkAP96KKNJswwvJZdL8epq7XdRp4OPHh5A99jgS/Z+V1S4mTVrFi+99BL5+fl06dKFV199lUGDBjW47YoVK5g9ezaZmZnU1tbSpUsXnnnmGW666aYmv5+EGyFEc1h7sJCJ87cC2hT7WoeLmGALs8emnvcPfHmNnef/vZ+l23IAaNfGn7hQP9aevdSk10G7NgEEWXwINBsJ8zdx78CkBu8ltHz7dxwrruTh61Mw+zQ8e+5AgTbou8rm5O6+8fgY9Ly/5QQ2hzZjKyUigHH9ErgtNYZ9eWU8ujTTPebI4dJODYEmIw9d344jhZV8vCsPm7NutteUIe2ZOqS9u8flq0OneOm/B+sFonNigi04XYqCMu09pg/vRIifL79etgudDhbe27fBQeU/ptrm5PN9BTy9ci8lVXaS2/jzzi/7EGT2YcL8LWTmlBBoNtIxMpBtx7V7Jfka9ThdCqfL8xRotfjQOzGEASnhjOkdX69n75zMnBIeeHcbheV10/KvPfuolKb0QNmdLo4XV3K4sAIfg57oYAvRVgtBlvoD/xdtPs6TH+wBIMhspKzGwYCUMOZP7HPeQe0XY/vx0zz/n/3c0j2aewYmNbhNabWdR5dmegTy6zq2YcEv+zR7e865YsLN0qVLGTduHLNmzWLAgAHMmTOHt956i3379hEfH19v+2nTphEdHc31119PcHAw8+fP5+WXX2bz5s306tWrSe8p4UYI0Vx+98Fu3t+sPYJiUPtw/j6mF6FNuBvxmgMneWL5bvcUdINex8ieMUy+IYWkRqbE/y8aul9RekIIU4a0Z1D7cI8TaUmVjSeWf8t/92r3RvpFWixP/KST+/LaqfJaFm0+ztdHipl0XTuu7xjR4HsWltew43gJO06cYfvxM2SdLKespm4WU1urmdfv6uXulZu+/FuWbM0hPMCX/0wZRGSQGaUUZ6rs1DqcBJiM+Psa0et1KKUoq3FwptLGseJKPt6Vz2d78qk82wvVMy6Ytyf2dv8cKmod3DN/K1uOnQa0UDO2bwIPXdcOf5OBzJwSth07w9Zjp9l+/Iy7NwsgNsTCs7d2YUjnSPe6WoeTD3fm8oeP9mJzuOgQGcCvh3Vk6pKd1NhdTBrcjunDO523LrPXHuHrI8UcPVXpERTPCTAZGdQ+nJ+nxjK4Qxs2Hinivne24XQpHh3agSGdI7hjztdU2ZzcnhbLX37RvUmzICtrHRw6WU77yEACTOcf9P+fb/N59J+Z7gD8+l29uLl7tMc2h06W88C72zhWXIXJqGfq0Pb89fNDOF2Kf03qT3ripeltvWLCTd++fUlNTWX27NnudZ07d2bkyJHMnDmzScfo0qULo0eP5qmnnmrS9hJuhBDNpbLWwQuf7CcxzI97ByZf0JiRM5U2/rrqIErB/YOSG73Pz8V67YssXll1iD6JoUwd2p6MdmHnPSEqpVh78BThASa6xVqb5f3PBZXsogpOldvonxzmcfmmxu5k5BsbOVBQTlK4P4FmI9lFlZR/LxDpdODva6Ta7qzX2wJaEPl5aiyTBifXm7FXZXPwwn/2YzIaeODaZKKsDY+NcThd7M0rY3N2MQs2HiOvtAaAYddEMrxbFGsOnGLtgUL3zSmHdo7k1TE9CTAZWbkrjymLdwLwf3f24pYedYGgrMbO3HVHmbch22OMkr+vgZSIAJxKkVdSw+lKzyniIX4+1DpcVNmcjEqN5eXbtSCz5sBJ7ntnGy4FQztH4GPQc7rSRlmNg37JoUy5ob3HIz82Hi7iN8t2uXvlesYFMyAlnL7JoXRpa8Xq54NSijlfHeXFT7XZiTHBFnJLqjH76PnXpAy6xmi/C18eLOSR93dSUesgJtjCnHEMDOYvAAAR1ElEQVRpdI2xMmPFtyzekkP/5DAWP+D5SJjmckWEG5vNhp+fH8uWLeO2225zr586dSqZmZmsW7fuR4/hcrlITEzk8ccfZ/LkyQ1uU1tbS21tXbdhWVkZcXFxEm6EEFeVsho7gaYLv9fR5XL0VAW3vr6RilrP+9R8/xLZ9/n7GggLMDGofTi39YohLSGkWT9blc3B37/IYt767HrvHxFoYnz/BH51XYrH+JyZn+5nzrqjmH30pMaHYNDrMOp1ZOaUcKbKDmg9S5MGJ9Ml2kpMsMVj/2qbk6zCclZm5vHRrjx3z15GuzAW/NLzEtR7Xx/jDx/tbbDtVosPjw5tzy/S43jl80O8vVEbgG7xMXiEq3OirWbaBJnZdXYc0sSMRH73087c9+42vjp0imirmZWPDOTjXXn88d/7cCnolxzKrLvT3D1kuSXVXP/SWmxOF4vu+98uL/6YKyLc5OXlERMTw8aNG8nIyHCv/9Of/sQ777zDwYMHf/QYL730Ei+++CL79+8nIqLh7tFnnnmGZ599tt56CTdCCNGyfPtdCVuyTxMX6kdSuD/xoX7u8UzlNQ4qah1YfAwE+/mcd5xRczt0spwXPz1AXkk113WMYFiXSHrGBjc46NjpUvxywVa+OnSq3mvt2vjz25s6cVOXyCaFMIfTxcYjxRwsKOPOPvHu2xV83xf7T7I7t5RQf19Czs6Ge+PLw+6ZYr5Gvfvy0th+8fzup50prrCx8XARGw4XkZlTwndn6mYn6nTwhxHXuMfZlFbZGTlrI9lFlbQJNLnD1h3psTw/slu98T7PrNzLgk3H6BUfzIqHMpo9SF9R4WbTpk3079/fvf6FF17gvffe48CBA43sDYsXL+a+++7jo48+YujQoefdTnpuhBBCXC4Op4v1WUWU1zpwulzYnYpgiw83dIrAaLj0D848N33/r58f4nSljTaBJv7yi+7nHR9VVmPn4NkbYnaJtrqn+p9zuLCC297YSHmtA50OZgzvxP2DkhsMLoXlNVz7ly+psbt4e2I6N3SKrLfNxbiQcOO1x8OGh4djMBgoKCjwWF9YWEhkZOMFWbp0Kffeey/Lli1rNNgAmEwmTKbz329BCCGEaC5Gg57rOzUcJC4Hg17H3X0TuLl7NOsOnWJQSrjH+JsfCjL70Dsx1H2rgR9KiQhgzrg03lh7mIkZSdx4zfnPzxGBZiZkJDJn3VH++vkhrusQ0eRp9c3Na89f9/X1JS0tjVWrVnmsX7Vqlcdlqh9avHgxEydO5P3332fEiBGXuplCCCHEFcdq8eHWHtGNBpumykgJZ9F9/RoNNudMurYdASYjfr4GzlRdgmdoNZHXem4AHnvsMcaNG0d6ejr9+/dn7ty5nDhxgkmTJgEwY8YMcnNzeffddwEt2IwfP56///3v9OvXz93rY7FYsFqbZ1S/EEIIIf43If6+fDp1ELEhFq8OXvdquBk9ejTFxcU899xz5Ofn07VrVz755BMSErTnruTn53PixAn39nPmzMHhcPDwww/z8MMPu9dPmDCBBQsWXO7mCyGEEOIH4kIv8UNUm8Drdyi+3OQ+N0IIIcSV50LO314bcyOEEEIIcSlIuBFCCCFEqyLhRgghhBCtioQbIYQQQrQqEm6EEEII0apIuBFCCCFEqyLhRgghhBCtioQbIYQQQrQqEm6EEEII0apIuBFCCCFEqyLhRgghhBCtioQbIYQQQrQqXn0quDece05oWVmZl1sihBBCiKY6d95uyvO+r7pwU15eDkBcXJyXWyKEEEKIC1VeXo7Vam10G51qSgRqRVwuF3l5eQQGBqLT6Zr12GVlZcTFxZGTk/Ojj2MXUq8LJfVqOqnVhZF6XRip14VprnoppSgvLyc6Ohq9vvFRNVddz41eryc2NvaSvkdQUJD8wl8AqdeFkXo1ndTqwki9LozU68I0R71+rMfmHBlQLIQQQohWRcKNEEIIIVoVwzPPPPOMtxvRmhgMBq677jqMxqvuit//ROp1YaReTSe1ujBSrwsj9bowl7teV92AYiGEEEK0bnJZSgghhBCtioQbIYQQQrQqEm6EEEII0apIuBFCCCFEqyLhppnMmjWLpKQkzGYzaWlprF+/3ttNahFmzpxJ7969CQwMJCIigpEjR3Lw4EGPbZRSPPPMM0RHR2OxWLjuuuvYu3evl1rccsycOROdTse0adPc66RWnnJzcxk7dixhYWH4+fnRs2dPtm/f7n5d6lXH4XDw+9//nqSkJCwWC8nJyTz33HO4XC73Nldzvb766ituueUWoqOj0el0fPjhhx6vN6U2tbW1PPLII4SHh+Pv78+tt97Kd999dzk/xmXTWL3sdjtPPPEE3bp1w9/fn+joaMaPH09eXp7HMS5pvZS4aEuWLFE+Pj7qzTffVPv27VNTp05V/v7+6vjx495umtfddNNNav78+WrPnj0qMzNTjRgxQsXHx6uKigr3Ni+++KIKDAxUy5cvV7t371ajR49Wbdu2VWVlZV5suXdt2bJFJSYmqu7du6upU6e610ut6pw+fVolJCSoiRMnqs2bN6vs7Gy1evVqdfjwYfc2Uq86zz//vAoLC1P//ve/VXZ2tlq2bJkKCAhQr776qnubq7len3zyiXryySfV8uXLFaA++OADj9ebUptJkyapmJgYtWrVKrVjxw51/fXXqx49eiiHw3G5P84l11i9SkpK1NChQ9XSpUvVgQMH1Ndff6369u2r0tLSPI5xKesl4aYZ9OnTR02aNMljXadOndT06dO91KKWq7CwUAFq3bp1SimlXC6XioqKUi+++KJ7m5qaGmW1WtU//vEPbzXTq8rLy1X79u3VqlWr1ODBg93hRmrl6YknnlADBw487+tSL08jRoxQ99xzj8e6n//852rs2LFKKanX9/3wZN2U2pSUlCgfHx+1ZMkS9za5ublKr9erzz777PI13gsaCoM/tGXLFgW4/6f/UtdLLktdJJvNxvbt2xk2bJjH+mHDhrFp0yYvtarlKi0tBSA0NBSA7OxsCgoKPOpnMpkYPHjwVVu/hx9+mBEjRjB06FCP9VIrTytXriQ9PZ3bb7+diIgIevXqxZtvvul+XerlaeDAgXzxxRccOnQIgF27drFhwwZ++tOfAlKvxjSlNtu3b8dut3tsEx0dTdeuXa/6+oH2t1+n0xEcHAxc+nrJrRUvUlFREU6nk8jISI/1kZGRFBQUeKlVLZNSiscee4yBAwfStWtXAHeNGqrf8ePHL3sbvW3JkiXs2LGDrVu31ntNauXp6NGjzJ49m8cee4zf/e53bNmyhSlTpmAymRg/frzU6weeeOIJSktL6dSpEwaDAafTyQsvvMCdd94JyO9XY5pSm4KCAnx9fQkJCam3zdV+LqipqWH69Oncdddd7gdnXup6SbhpJjqdzuN7pVS9dVe7yZMn8+2337Jhw4Z6r0n9ICcnh6lTp/L5559jNpvPu53USuNyuUhPT+dPf/oTAL169WLv3r3Mnj2b8ePHu7eTemmWLl3KwoULef/99+nSpQuZmZlMmzaN6OhoJkyY4N5O6nV+/0ttrvb62e12xowZg8vlYtasWT+6fXPVSy5LXaTw8HAMBkO9pFlYWFgv5V/NHnnkEVauXMmXX35JbGyse31UVBSA1A+tm7awsJC0tDSMRiNGo5F169bx2muvYTQa3fWQWmnatm3LNddc47Guc+fOnDhxApDfrR/67W9/y/Tp0xkzZgzdunVj3LhxPProo8ycOROQejWmKbWJiorCZrNx5syZ825ztbHb7dxxxx1kZ2ezatUqd68NXPp6Sbi5SL6+vqSlpbFq1SqP9atWrSIjI8NLrWo5lFJMnjyZFStWsGbNGpKSkjxeT0pKIioqyqN+NpuNdevWXXX1GzJkCLt37yYzM9O9pKenc/fdd5OZmUlycrLU6nsGDBhQ77YChw4dIiEhAZDfrR+qqqpCr/f8k28wGNxTwaVe59eU2qSlpeHj4+OxTX5+Pnv27Lkq63cu2GRlZbF69WrCwsI8Xr/k9broIcnCPRV83rx5at++fWratGnK399fHTt2zNtN87qHHnpIWa1WtXbtWpWfn+9eqqqq3Nu8+OKLymq1qhUrVqjdu3erO++886qZfvpjvj9bSimp1fdt2bJFGY1G9cILL6isrCy1aNEi5efnpxYuXOjeRupVZ8KECSomJsY9FXzFihUqPDxcPf744+5truZ6lZeXq507d6qdO3cqQL3yyitq586d7tk9TanNpEmTVGxsrFq9erXasWOHuuGGG1rtVPDG6mW329Wtt96qYmNjVWZmpsff/traWvcxLmW9JNw0kzfeeEMlJCQoX19flZqa6p7qfLUDGlzmz5/v3sblcqmnn35aRUVFKZPJpK699lq1e/du7zW6BflhuJFaefr4449V165dlclkUp06dVJz5871eF3qVaesrExNnTpVxcfHK7PZrJKTk9WTTz7pcbK5muv15ZdfNvi3asKECUqpptWmurpaTZ48WYWGhiqLxaJuvvlmdeLECS98mkuvsXplZ2ef92//l19+6T7GpayXTimlLr7/RwghhBCiZZAxN0IIIYRoVSTcCCGEEKJVkXAjhBBCiFZFwo0QQgghWhUJN0IIIYRoVSTcCCGEEKJVkXAjhBBCiFZFwo0QQgghWhUJN0KIFqOwsJAHH3yQ+Ph4TCYTUVFR3HTTTXz99deA9lTmDz/80MutFEK0dEZvN0AIIc4ZNWoUdrudd955h+TkZE6ePMkXX3zB6dOnvd00IcQVRHpuhBAtQklJCRs2bODPf/4z119/PQkJCfTp04cZM2YwYsQIEhMTAbjtttvQ6XTu7wE+/vhj0tLSMJvNJCcn8+yzz+JwONyv63Q6Zs+ezfDhw7FYLCQlJbFs2TL36zabjcmTJ9O2bVvMZjOJiYnMnDnzcn10IUQzk3AjhGgRAgICCAgI4MMPP6S2trbe61u3bgVg/vz55Ofnu7//73//y9ixY5kyZQr79u1jzpw5LFiwgBdeeMFj/z/84Q+MGjWKXbt2MXbsWO688072798PwGuvvcbKlSv55z//ycGDB1m4cKFHeBJCXFnkwZlCiBZj+fLl3H///VRXV5OamsrgwYMZM2YM3bt3B7QemA8++ICRI0e697n22msZPnw4M2bMcK9buHAhjz/+OHl5ee79Jk2axOzZs93b9OvXj9TUVGbNmsWUKVPYu3cvq1evRqfTXaZPK4S4VKTnRgjRYowaNYq8vDxWrlzJTTfdxNq1a0lNTWXBggXn3Wf79u0899xz7p6fgIAA7r//fvLz86mqqnJv179/f4/9+vfv7+65mThxIpmZmXTs2JEpU6bw+eefX5LPJ4S4PCTcCCFaFLPZzI033shTTz3Fpk2bmDhxIk8//fR5t3e5XDz77LNkZma6l927d5OVlYXZbG70vc710qSmppKdnc0f//hHqqurueOOO/jFL37RrJ9LCHH5SLgRQrRo11xzDZWVlQD4+PjgdDo9Xk9NTeXgwYOkpKTUW/T6uj9x33zzjcd+33zzDZ06dXJ/HxQUxOjRo3nzzTdZunQpy5cvl1laQlyhZCq4EKJFKC4u5vbbb+eee+6he/fuBAYGsm3bNv7yl7/ws5/9DIDExES++OILBgwYgMlkIiQkhKeeeoqbb76ZuLg4br/9dvR6Pd9++y27d+/m+eefdx9/2bJlpKenM3DgQBYtWsSWLVuYN28eAH/7299o27YtPXv2RK/Xs2zZMqKioggODvZKLYQQF0kJIUQLUFNTo6ZPn65SU1OV1WpVfn5+qmPHjur3v/+9qqqqUkoptXLlSpWSkqKMRqNKSEhw7/vZZ5+pjIwMZbFYVFBQkOrTp4+aO3eu+3VAvfHGG+rGG29UJpNJJSQkqMWLF7tfnzt3rurZs6fy9/dXQUFBasiQIWrHjh2X7bMLIZqXzJYSQrR6Dc2yEkK0XjLmRgghhBCtioQbIYQQQrQqMqBYCNHqydV3Ia4u0nMjhBBCiFZFwo0QQgghWhUJN0IIIYRoVSTcCCGEEKJVkXAjhBBCiFZFwo0QQgghWhUJN0IIIYRoVSTcCCGEEKJVkXAjhBBCiFbl/wHnpZapJM5UDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "loss_tracker.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f867f-d4ed-4cb2-a5f7-e045e0902fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(\"rosgpt_zephyr_lora\")\n",
    "trainer.tokenizer.save_pretrained(\"rosgpt_zephyr_lora\")\n",
    "trainer.model.config.save_pretrained(\"rosgpt_zephyr_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccca2b5b-94ac-49ec-a9af-ca1adc12d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, TrainerCallback, AutoConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e91d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set Model ID (Replace with your model)\n",
    "model_id = \"SeaLLMs/SeaLLMs-v3-7B-Chat\"  # Example, change if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b6010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1972 examples [00:00, 53345.16 examples/s]\n",
      "Generating train split: 676 examples [00:00, 74935.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Datasets (Ensure paths are correct)\n",
    "train_dataset = load_dataset('json', data_files=r'C:\\Users\\BNC\\Documents\\ITC-Internship\\LLM\\LLM-Model\\visal\\split_data\\train.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files=r'C:\\Users\\BNC\\Documents\\ITC-Internship\\LLM\\LLM-Model\\visal\\split_data\\valid.jsonl', split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75d0aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvannvisal1012\u001b[0m (\u001b[33mvannvisal1012-institute-of-tecnology-of-cambodia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\BNC\\Downloads\\Telegram Desktop\\GPTForRobotics-dev\\GPTForRobotics-dev\\finetuning_model\\wandb\\run-20250220_081514-2fdajf95</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune/runs/2fdajf95' target=\"_blank\">dauntless-wildflower-9</a></strong> to <a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune' target=\"_blank\">https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune/runs/2fdajf95' target=\"_blank\">https://wandb.ai/vannvisal1012-institute-of-tecnology-of-cambodia/fine-tune/runs/2fdajf95</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize WandB (Optional)\n",
    "wandb_config = {\"model\": model_id}\n",
    "wandb.init(project=\"fine-tune\", config=wandb_config)\n",
    "\n",
    "# 4-Bit Quantization Configuration (Optimized for Low VRAM)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247b73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ID\n",
    "model_id = \"SeaLLMs/SeaLLMs-v3-7B-Chat\"\n",
    "\n",
    "# Hugging Face token\n",
    "hf_token = \"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\"  # Replace with your token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe17ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [13:38<00:00, 204.57s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map={\"\": \"cpu\"},\n",
    "    offload_folder=\"offload\",  # Moves some weights to disk to free memory\n",
    "    torch_dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4399b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Could not find module 'c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "CUDA SETUP: Loading binary c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Could not find module 'c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6296\\3576664663.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 📌 Load Model with Quantization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             return model_class.from_pretrained(\n\u001b[0m\u001b[0;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3657\u001b[1;33m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[0;32m   3658\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3659\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mbnb_multibackend_is_enabled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_bitsandbytes_multi_backend_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mvalidate_bnb_backend_availability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_exception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"from_tf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"from_flax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\integrations\\bitsandbytes.py\u001b[0m in \u001b[0;36mvalidate_bnb_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_bitsandbytes_multi_backend_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_validate_bnb_multi_backend_availability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_validate_bnb_cuda_backend_availability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\integrations\\bitsandbytes.py\u001b[0m in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Model with Quantization\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # Auto-distribute between GPU & CPU\n",
    "    offload_folder=\"offload\",  # Offload to CPU if needed\n",
    "    use_cache=False  # Disable cache to prevent OOM errors\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6f7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e97a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lora (Fine-Tuning) Configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2fe4c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Model for LoRA Training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32f9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Construct Prompts for Training\n",
    "def create_prompt_universal(examples):\n",
    "    output_text = []\n",
    "    for i in range(len(examples[\"input\"])):\n",
    "        input_text = examples[\"input\"][i]\n",
    "        response = examples[\"output\"][i]\n",
    "\n",
    "        chat_template = [{\"role\": \"user\", \"content\": input_text}, {\"role\": \"assistant\", \"content\": response}]\n",
    "        prompt = tokenizer.apply_chat_template(chat_template, tokenize=False)\n",
    "\n",
    "        output_text.append(prompt)\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3bac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Compute Metrics\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]  # Extract main logits if extra tensors exist\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training Arguments (Optimized for 4GB VRAM)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"instruct_generation\",\n",
    "    max_steps=500,  # Reduce from 1200 to 500\n",
    "    per_device_train_batch_size=2,  # Reduce batch size to fit memory\n",
    "    gradient_accumulation_steps=4,  # Accumulate gradients to simulate larger batch\n",
    "    warmup_steps=0,\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,  # Evaluate every 20 steps\n",
    "    learning_rate=2e-5,  # Slightly increased learning rate\n",
    "    bf16=True if torch.cuda.is_available() else False,  # Use BF16 if GPU supports it\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"wandb\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9df150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "191d0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss Tracking Callback for Monitoring\n",
    "class LossTrackerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.training_loss_values = []\n",
    "        self.eval_loss_values = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if \"loss\" in logs:\n",
    "            self.training_loss_values.append(logs[\"loss\"])\n",
    "        if \"eval_loss\" in logs:\n",
    "            self.eval_loss_values.append(logs[\"eval_loss\"])\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        plt.plot(self.training_loss_values, label=\"Training Loss\")\n",
    "        plt.plot(self.eval_loss_values, label=\"Evaluation Loss\")\n",
    "        plt.xlabel(\"Steps\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Learning Curve\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "loss_tracker = LossTrackerCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "158b6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_universal(examples):\n",
    "    output_text = []\n",
    "    \n",
    "    # Check available column names\n",
    "    available_columns = examples.keys()\n",
    "    \n",
    "    # Find the correct keys\n",
    "    input_key = \"input\" if \"input\" in available_columns else list(available_columns)[0]\n",
    "    output_key = \"output\" if \"output\" in available_columns else list(available_columns)[1]\n",
    "\n",
    "    for i in range(len(examples[input_key])):\n",
    "        input_text = examples[input_key][i]\n",
    "        response = examples[output_key][i]\n",
    "\n",
    "        chat_template = [{\"role\": \"user\", \"content\": input_text}, {\"role\": \"assistant\", \"content\": response}]\n",
    "        prompt = tokenizer.apply_chat_template(chat_template, tokenize=False)\n",
    "\n",
    "        output_text.append(prompt)\n",
    "\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "295b8205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Could not find module 'c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "CUDA SETUP: Loading binary c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n",
      "Could not find module 'c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\bitsandbytes\\cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 1972/1972 [00:01<00:00, 1612.84 examples/s]\n",
      "Map: 100%|██████████| 676/676 [00:00<00:00, 4765.89 examples/s]\n",
      "c:\\Users\\BNC\\anaconda3\\envs\\airsim_env\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=128,  # Reduce sequence length to fit memory\n",
    "    tokenizer=tokenizer,\n",
    "    formatting_func=create_prompt_universal,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    callbacks=[loss_tracker],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d428a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "  2%|▏         | 12/500 [5:54:52<222:23:09, 1640.55s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start Training\n",
    "trainer.train()\n",
    "\n",
    "# Plot Learning Curve\n",
    "loss_tracker.plot_learning_curve()\n",
    "\n",
    "# Save Trained Model\n",
    "os.makedirs(\"rosgpt_seallm_lora\", exist_ok=True)\n",
    "trainer.model.save_pretrained(\"rosgpt_seallm_lora\")\n",
    "trainer.tokenizer.save_pretrained(\"rosgpt_seallm_lora\")\n",
    "trainer.model.config.save_pretrained(\"rosgpt_seallm_lora\")\n",
    "\n",
    "print(\"Training Complete! Model Saved as 'rosgpt_seallm_lora'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7d088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airsim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
